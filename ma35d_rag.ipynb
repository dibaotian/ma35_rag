{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# # LLamaIndex 使用 PyTorch 进行向量计算\n",
    "# # 清理GPU 资源\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # 垃圾回收\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    " # --can not run in notebook, run it in cmdline\n",
    "# ! nvidia-smi --gpu-reset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 数量： 2\n",
      "GPU 0: Tesla V100-PCIE-16GB，内存使用情况：1984.5625 MB / 16384.0 MB\n",
      "GPU 1: Tesla V100-PCIE-16GB，内存使用情况：1984.5625 MB / 16384.0 MB\n",
      "当前系统内存使用信息 pmem(rss=77746176, vms=720179200, shared=16588800, text=2818048, lib=0, data=148160512, dirty=0)\n",
      "物理内存中实际驻留的大小 0.07240676879882812 GB\n",
      "虚拟内存的大小，包括实际使用的物理内存和交换空间 0.6707191467285156 GB\n",
      "共享内存的大小，被多个进程共享的内存量 0.01544952392578125 GB\n",
      "可执行程序的代码段大小 0.00262451171875 GB\n",
      "程序的数据段大小 0.1379852294921875 GB\n"
     ]
    }
   ],
   "source": [
    "# %pip install nvidia-ml-py3\n",
    "import pynvml\n",
    "# 初始化 NVML 库\n",
    "pynvml.nvmlInit()\n",
    "\n",
    "# 获取 GPU 数量\n",
    "num_gpus = pynvml.nvmlDeviceGetCount()\n",
    "print(\"GPU 数量：\", num_gpus)\n",
    "\n",
    "# 遍历每个 GPU，获取其资源信息\n",
    "for i in range(num_gpus):\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "    gpu_name = pynvml.nvmlDeviceGetName(handle)\n",
    "    gpu_memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU {i}: {gpu_name.decode()}，内存使用情况：{gpu_memory_info.used / 1024 / 1024} MB / {gpu_memory_info.total / 1024 / 1024} MB\")\n",
    "\n",
    "# 关闭 NVML 库\n",
    "pynvml.nvmlShutdown()\n",
    "\n",
    "import psutil\n",
    "# 获取当前进程的内存信息\n",
    "process = psutil.Process()\n",
    "mem_info = process.memory_info()\n",
    "print(\"当前系统内存使用信息\",mem_info)\n",
    "print(\"物理内存中实际驻留的大小\", mem_info.rss/(1024*1024*1024), \"GB\")\n",
    "print(\"虚拟内存的大小，包括实际使用的物理内存和交换空间\", mem_info.vms/(1024*1024*1024), \"GB\")\n",
    "print(\"共享内存的大小，被多个进程共享的内存量\", mem_info.shared/(1024*1024*1024), \"GB\")\n",
    "print(\"可执行程序的代码段大小\", mem_info.text/(1024*1024*1024), \"GB\")\n",
    "print(\"程序的数据段大小\", mem_info.data/(1024*1024*1024), \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xilinx/Documents/llamaindex_ma35_rag/.venv/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "05/04/2024 12:36:20 - [INFO] -sentence_transformers.SentenceTransformer->>>    Load pretrained SentenceTransformer: maidalun1020/bce-embedding-base_v1\n",
      "/home/xilinx/Documents/llamaindex_ma35_rag/.venv/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "05/04/2024 12:36:25 - [INFO] -sentence_transformers.SentenceTransformer->>>    2 prompts are loaded, with the keys: ['query', 'text']\n",
      "05/04/2024 12:36:27 - [INFO] -BCEmbedding.models.RerankerModel->>>    Loading from `maidalun1020/bce-reranker-base_v1`.\n",
      "05/04/2024 12:36:28 - [INFO] -BCEmbedding.models.RerankerModel->>>    Execute device: cuda;\t gpu num: 2;\t use fp16: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %pip install llama-index-llms-ollama\n",
    "# !pip install llama-index\n",
    "# %pip install llama-index-embeddings-ollama\n",
    "# %pip install docx2txt\n",
    "# %pip install llama-index-embeddings-huggingface\n",
    "# %pip install llama-index-embeddings-instructor\n",
    "\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# load the ollama\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from BCEmbedding.tools.llama_index import BCERerank\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# model set\n",
    "llama2_7b = \"llama2\"\n",
    "llama2_13b = \"llama2:13b\"\n",
    "llama3_8b = \"llama3\"\n",
    "llama3_70b = \"llama3:70b\"\n",
    "\n",
    "\n",
    "# embedding_type = \"llama3\"\n",
    "embedding_type = \"bce\"\n",
    "rebuild = False\n",
    "\n",
    "if embedding_type == \"llama3\":\n",
    "    base_name = \"ma35_rag_base\"\n",
    "    embedding_model = OllamaEmbedding(model_name=llama3_8b,ollama_additional_kwargs={\"mirostat\": 0}) #base_url=\"http://localhost:11434\"\n",
    "elif embedding_type == \"bce\":\n",
    "    base_name = \"ma35_rag_base_bce\"\n",
    "    embed_args = {'model_name': 'maidalun1020/bce-embedding-base_v1', 'max_length': 512, 'embed_batch_size': 256, 'device': 'cuda'}\n",
    "    embedding_model = HuggingFaceEmbedding(**embed_args)\n",
    "else:\n",
    "    print(\"embedding model not correct\\n\")\n",
    "    exit(-1)\n",
    "\n",
    "# connect with the ollama server\n",
    "llm_llama = Ollama(model=llama3_8b, request_timeout=600, temperature=0.1, device='cuda') #base_url = 'http://localhost:11434',\n",
    "# llm_llama2 = Ollama(model=\"llama2:13b\", request_timeout=600, temperature=0.1) #base_url = 'http://localhost:11434',\n",
    "\n",
    "reranker_args = {'model': 'maidalun1020/bce-reranker-base_v1', 'top_n': 5, 'device': 'cuda'}\n",
    "reranker_model = BCERerank(**reranker_args)\n",
    "\n",
    "Settings.llm = llm_llama\n",
    "Settings.embed_model = embedding_model\n",
    "Settings.node_parser = SentenceSplitter(chunk_size=500, chunk_overlap=20)\n",
    "# Settings.num_output = 512\n",
    "# Settings.context_window = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:36:29 - [INFO] -chromadb.telemetry.product.posthog->>>    Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "# create a vector storage\n",
    "# %pip install llama-index-vector-stores-chroma\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "# initialize client, setting path to save data\n",
    "chroma_client = chromadb.PersistentClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# define prompt viewing function\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"<br><br>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if rebuild :\n",
    "    # %pip install llama-index-readers-web\n",
    "\n",
    "    from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "    documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "        [\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/index.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/getting_started_on_prem.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/virtualization.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/ffmpeg/tutorials.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/ffmpeg/quality_analysis.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/ffmpeg/filters.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/gstreamer/tutorials.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/gstreamer/filters.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/gstreamer/xcompositor.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/gstreamer/xabrladder.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/xma/xma_apps.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/specs_and_features.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/package_feed.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/using_ffmpeg.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/using_gstreamer.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/unified_logging.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/tuning_video_quality.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/tuning_pipeline_latency.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/managing_compute_resources.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/c_apis.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/card_management.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/encoder_comp_matrix.html\",\n",
    "        \"https://ffmpeg.org/ffmpeg.html\",\n",
    "        \"https://ffmpeg.org/ffmpeg-resampler.html\",\n",
    "        \"https://ffmpeg.org/ffmpeg-devices.html\",\n",
    "        \"https://ffmpeg.org/ffmpeg-all.html\",\n",
    "        \"https://trac.ffmpeg.org/wiki/Encode/H.264\",\n",
    "        \"https://trac.ffmpeg.org/wiki/Encode/H.265\",\n",
    "        \"https://trac.ffmpeg.org/wiki/Encode/AV1\",\n",
    "        \"https://trac.ffmpeg.org/wiki/Scaling\",\n",
    "        \"https://trac.ffmpeg.org/wiki/Null\",\n",
    "        \"https://trac.ffmpeg.org/wiki/FilteringGuide\",\n",
    "        ]\n",
    "        \n",
    "    )\n",
    "\n",
    "    collection_name = base_name\n",
    "    collection = chroma_client.list_collections()\n",
    "    if collection_name in collection:\n",
    "        chroma_client.delete_collection(collection_name)\n",
    "        chroma_client.clear_system_cache()\n",
    "    chroma_collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    storage_context = StorageContext.from_defaults(docstore=documents, vector_store=vector_store)\n",
    "\n",
    "    # 这个nodes 有什么用处\n",
    "    from llama_index.core.node_parser import SimpleNodeParser \n",
    "    # Initialize the parser \n",
    "    parser = SimpleNodeParser.from_defaults(chunk_size=500, chunk_overlap=20) \n",
    "    # Parse documents into nodes \n",
    "    nodes = parser.get_nodes_from_documents(documents)\n",
    "    # print(nodes[0])\n",
    "    len(nodes)\n",
    "\n",
    "    # %pip install ipywidgets\n",
    "    # index = VectorStoreIndex.from_documents(documents,storage_context=storage_context,show_progress=True)\n",
    "    index = VectorStoreIndex(nodes,embed_model=embedding_model,storage_context=storage_context,show_progress=True)\n",
    "\n",
    "    # # documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # 读取 HTML 文件\n",
    "# with open(\"local_html/FFMPEG command line arguments - VideoDC - Xilinx Enterprise Wiki.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "#     html_content = file.read()\n",
    "\n",
    "# # 使用 Beautiful Soup 解析 HTML\n",
    "# soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# # 提取文档内容\n",
    "# document_text = soup.get_text()\n",
    "\n",
    "# # 打印文档内容\n",
    "# print(document_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from stored vectors\n",
    "collection_name = base_name\n",
    "collection = chroma_client.list_collections()\n",
    "chroma_collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store, embed_model=embedding_model,storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "   \"\"\"explain following ffmpeg command \"ffmpeg -hwaccel ama -f rawvideo -s 1920x1080 -framerate 24 -i cut1_1080p.nv12 -vf 'hwupload' -c:v av1_ama -b:v 5M -f mp4 -y 1.av1_1080p_1.mp4\" \"\"\",\n",
    "\n",
    "   \"\"\"explain following ffmpeg command\n",
    "   ffmpeg -y -hwaccel ama \\\n",
    "      -c:v h264_ama  -out_fmt nv12 -i <INPUT>  \\\n",
    "      -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d]; \\\n",
    "                     [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\" \\\n",
    "      -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv \\\n",
    "      -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv  \\\n",
    "      -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv \\\n",
    "      -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\"\"\",\n",
    "\n",
    "    \n",
    "    \"\"\"Using ffmpeg Decoder a clip that is already encoded in H.264, and will decode the file into a RAW format and save it to disk.\"\"\",\n",
    "    \"\"\"Using ffmpeg encode a RAW 1080p60 clip in YUV420 format. Pass the clip to the MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and saves it to disk. please do not use -re option\"\"\",\n",
    "    \"\"\" Using ffmpeg do the Bit Conversion, To encode YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format' \"\"\",\n",
    "    \"\"\" Using ffmpeg decodes an existing H.264 file and then scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk\"\"\",\n",
    "    \"\"\" Using ffmpeg one cmd line, decodes an existing H.264 file and then using scaler_ama scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk\"\"\",\n",
    "\n",
    "    \"\"\"How to tuning Latency of MA35D ama codec video transcode,  for example enable ultra low latency for ama_av1 Encoding?\"\"\",\n",
    "    \n",
    "    \"一个ma35D AV1 codec transcode 的处理能力是多少 \",\n",
    "\n",
    "   # the question come from forum\n",
    "    \"\"\"Is max_bitrate implemented in ama sdk ffmpeg, and is it correct that the max bitrate parameter in AMA is irrelevant to VBR?\"\"\",\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = index.as_retriever()\n",
    "# relevant_docs = retriever.retrieve(\"what is the max transcode rate for 1080p30 stream\")\n",
    "# relevant_docs\n",
    "\n",
    "# \"\"\"\n",
    "# response_mode\n",
    "\n",
    "#     REFINE = \"refine\"\n",
    "#     COMPACT = \"compact\"\n",
    "#     SIMPLE_SUMMARIZE = \"simple_summarize\"\n",
    "#     TREE_SUMMARIZE = \"tree_summarize\"\n",
    "#     GENERATION = \"generation\"\n",
    "#     NO_TEXT = \"no_text\"\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# ResponseMode为tree_summarize时，LLM会对每一段文本进行最大长度的分割，并进行连续的读取和询问。这种模式的优点是可以保证对文本的完整理解和回答，但如果没有正确处理分割段落的情况，可能会导致错误的生成结果\n",
    "# ResponseMode为generation时，生成的回答不依赖于文档的内容，只基于提供的问题进行生成。这种模式适用于纯粹的问题回\n",
    "# ResponseMode为no_text时，生成的回答中不包含任何内容，仅作为占位符使用\n",
    "# ResponseMode为simple_summarize时，LLM会截取每段文本的相关句子（通常是第一句），并进行提炼生成回答。这种模式适用于对结果要求不高的场景。\n",
    "# ResponseMode为refine时，如果只有一个文本块（text_chunk），则会正常生成回答。但如果存在多个文本块，则会以类似轮询的方式迭代生成回答。这种模式可以对多个文本块进行迭代式的回答生成，逐步完善回答内容。\n",
    "# ResponseMode为compact时，生成的回答会将多个文本块（text_chunk）压缩到设定的最大长度，并生成一次回答。然后，根据后续内容对以往的答案进行改进和完善（即进行多次迭代）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are hellpful, respectful and honest video transcode assistant and very faimilay with ffmpge, and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/transcode.\n",
      "Context information from multiple sources is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the information from multiple sources and not prior knowledge\n",
      "please read the above context information carefully. and anwer the question.\n",
      "if the question is not releate with video process, just say it is not releated with my knowledge base.\n",
      "if you don't know the answer, just say that I don't know.\n",
      "Answers need to be precise and concise.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "query_engine = index.as_query_engine(response_mode='simple_summarize', similary_threshold=0.1, similarity_top_k=5)\n",
    "\n",
    "template = (\n",
    "    \"You are hellpful, respectful and honest video transcode assistant and very faimilay with ffmpge, and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/transcode.\\n\"\n",
    "    \"Context information from multiple sources is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the information from multiple sources and not prior knowledge\\n\"\n",
    "    \"please read the above context information carefully. and anwer the question.\\n\"\n",
    "    \"if the question is not releate with video process, just say it is not releated with my knowledge base.\\n\"\n",
    "    \"if you don't know the answer, just say that I don't know.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_template}\n",
    ")\n",
    "\n",
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "286d9d363f454d11b4bebe989ecea5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:36:43 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1: explain following ffmpeg command \"ffmpeg -hwaccel ama -f rawvideo -s 1920x1080 -framerate 24 -i cut1_1080p.nv12 -vf 'hwupload' -c:v av1_ama -b:v 5M -f mp4 -y 1.av1_1080p_1.mp4\" \n",
      "Answer:This FFmpeg command is used to encode a raw video file into an MP4 container using the AV1 codec with hardware acceleration.\n",
      "\n",
      "Here's a breakdown of the command:\n",
      "\n",
      "* `-hwaccel ama`: This flag enables the AMD MultiMedia Accelerator (AMA) hardware accelerator for FFmpeg.\n",
      "* `-f rawvideo`: This flag specifies that the input file is in raw video format.\n",
      "* `-s 19:20x10:80`: This flag sets the resolution of the input file to 1920x1080 pixels.\n",
      "* `-framerate 24`: This flag sets the frame rate of the input file to 24 frames per second.\n",
      "* `-i cut1_10:80p.nv12`: This flag specifies the input file, which is a raw video file named `cut1_10:80p.nv12` with a resolution of 1920x1080 pixels and a frame rate of 24 fps.\n",
      "* `-vf 'hwupload'`: This flag applies the `hwupload` filter to the input file. The `hwupload` filter is used to upload the raw video data to the AMA hardware accelerator for processing.\n",
      "* `-c:v av1_ama`: This flag specifies that the output video codec should be AV1 with hardware acceleration using the AMA hardware accelerator.\n",
      "* `-b:v 5M`: This flag sets the target bitrate of the encoded video stream to 5 megabits per second.\n",
      "* `-f mp4`: This flag specifies that the output file should be in MP4 container format.\n",
      "* `-y 1.av1_10:80p_1.mp4`: This flag specifies the output file name, which is `1.av1_10:80p_1.mp4`.\n",
      "\n",
      "In summary, this FFmpeg command encodes a raw video file into an MP4 container using the AV1 codec with hardware acceleration from the AMD MultiMedia Accelerator (AMA).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fec8b01e3374e1fa8171ab15948d4c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:36:56 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question2: explain following ffmpeg command\n",
      "   ffmpeg -y -hwaccel ama       -c:v h264_ama  -out_fmt nv12 -i <INPUT>        -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d];                      [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\"       -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv       -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv        -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv       -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "Answer:This FFmpeg command is used to scale a video input to four different resolutions (1920x1080, 1280x720, 720x480, and 360x240) using the `scaler_ama` filter, which is a hardware-accelerated scaler. The output of each resolution is then written to a separate YUV file.\n",
      "\n",
      "Here's a breakdown of the command:\n",
      "\n",
      "* `-y`: Overwrite existing files without asking.\n",
      "* `-hwaccel ama`: Use the AMA (AMD MultiMedia Accelerator) hardware accelerator for video processing.\n",
      "* `-c:v h264_ama`: Set the video codec to H.264, using the AMA hardware accelerator.\n",
      "* `-out_fmt nv12`: Set the output format to NV12 (a planar YUV format).\n",
      "* `-i <INPUT>`: Specify the input file.\n",
      "* `filter_complex`: Apply a complex filter graph to the input stream.\n",
      "\n",
      "The filter graph consists of two parts:\n",
      "\n",
      "1. The first part scales the input video to four different resolutions using the `scaler_ama` filter:\n",
      "\t* `scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d];`\n",
      "\t\t+ This sets up four output streams, each with a different resolution.\n",
      "\t\t+ The `[a]`, `[b]`, `[c]`, and `[d]` labels are used to identify the outputs.\n",
      "2. The second part downloads each of the scaled outputs and formats them as NV12:\n",
      "\t* `hwdownload,format=nv12[a1]; [b]hwdownload,format=nv12[b1]; [c]hwdownload,format=nv12[c1]; [d]hwdownload,format=nv12[d1];`\n",
      "\t\t+ This downloads each of the scaled outputs and formats them as NV12.\n",
      "\n",
      "The command then maps each of the formatted outputs to a separate YUV file using the `-map` option:\n",
      "\n",
      "* `map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv`\n",
      "\t+ This writes the output labeled `[a1]` (the 1920x1080 resolution) to a file named `/tmp/scale_1080p.yuv`.\n",
      "* `map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv`\n",
      "\t+ This writes the output labeled `[b1]` (the 1280x720 resolution) to a file named `/tmp/scale_720p.yuv`.\n",
      "* `map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv`\n",
      "\t+ This writes the output labeled `[c1]` (the 720x480 resolution) to a file named `/tmp/scale_480p.yuv`.\n",
      "* `map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv`\n",
      "\t+ This writes the output labeled `[d1]` (the 360x240 resolution) to a file named `/tmp/scale_240p.yuv`.\n",
      "\n",
      "In summary, this command takes an input video and scales it to four different resolutions using the `scaler_ama` filter. The outputs are then written to separate YUV files.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e061b9e9b0c54b8dbb24780e6995c0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:36:59 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question3: Using ffmpeg Decoder a clip that is already encoded in H.264, and will decode the file into a RAW format and save it to disk.\n",
      "Answer:To use FFmpeg to decode a clip that is already encoded in H.264 and save it to disk in RAW format, you can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> -vf hwdownload,format=nv12 -f rawvideo /tmp/dec_out.nv12\n",
      "```\n",
      "\n",
      "This command uses the FFmpeg application with AMD AMA Video SDK acceleration to decode the H.264 encoded clip and save it as a RAW file in NV12 format.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544fa55b7e27486b8693c6f92d71d94a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:37:03 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question4: Using ffmpeg encode a RAW 1080p60 clip in YUV420 format. Pass the clip to the MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and saves it to disk. please do not use -re option\n",
      "Answer:Here is the command:\n",
      "\n",
      "```\n",
      "ffmpeg -hwaccel ama -i <INPUT> -vf \"hwupload\" -c:v av1_ama -b:v 5M -f mp4 -y sn1_av1.mp4\n",
      "```\n",
      "\n",
      "This command uses the MA35D (AMA) hardware accelerator to encode a RAW 10.80p60 clip in YUV420 format using the AV1 codec with a target bitrate of 5Mbps and saves it to disk as an MP4 file. The `-re` option is not used, as per your request.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716ed49b5dda45df8cb8dfde039be6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:37:07 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question5:  Using ffmpeg do the Bit Conversion, To encode YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format' \n",
      "Answer:To encode YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format using ffmpeg, you can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -hwaccel ama -i <INPUT> -vf \"format=yuv420p,hwupload\" -c:v h264_ama -b:v 1M <OUTPUT>\n",
      "```\n",
      "\n",
      "This command uses the `format` filter to convert the input YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format. The `hwupload` filter is used to upload and convert the input video as `yuv420p`. The `h264_ama` codec is used for encoding, with a target bitrate of 1M.\n",
      "\n",
      "Note that you may need to manually set the SAR value to 1:1 to make the players display it in the way you want.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b14106c404de4b268305d4ac05c232fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:37:13 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question6:  Using ffmpeg decodes an existing H.264 file and then scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:Based on the provided context information, I can help you with that.\n",
      "\n",
      "To decode an existing H.264 file and scale it into different resolutions (10, 80, 720, 480, or 240 p), you can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -i input.mp4 -vf scale=w:h -c:v libx264 -b:v 1M output_1080p.mp4\n",
      "ffmpeg -i input.mp4 -vf scale=w:h -c:v libx264 -b:v 1M output_720p.mp4\n",
      "ffmpeg -i input.mp4 -vf scale=w:h -c:v libx264 -b:v 1M output_480p.mp4\n",
      "ffmpeg -i input.mp4 -vf scale=w:h -c:v libx264 -b:v 1M output_240p.mp4\n",
      "```\n",
      "\n",
      "Replace `input.mp4` with the path to your existing H.264 file, and `w` and `h` with the desired width and height for each resolution.\n",
      "\n",
      "Note that this command will not produce RAW outputs but rather encoded MP4 files at the specified resolutions. If you need RAW outputs, please clarify what you mean by \"RAW\" in this context.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8755ad2bf584dc9aada27baac0ddcba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:37:19 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question7:  Using ffmpeg one cmd line, decodes an existing H.264 file and then using scaler_ama scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:Based on the provided context information, here is a possible command line that achieves the desired result:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d]; [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\" -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "```\n",
      "\n",
      "This command line uses the `scaler_ama` filter to scale the input H.264 file into four different resolutions (1920x1080, 1280x720, 720x480, and 360x240) and saves the RAW outputs as YUV files under `/tmp/`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae57abdc9b643dd935bc9d4bd0326a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:37:23 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question8: How to tuning Latency of MA35D ama codec video transcode,  for example enable ultra low latency for ama_av1 Encoding?\n",
      "Answer:According to the provided context information, to enable Ultra Low Latency (ULL) mode for AMA AV1 encoding, you can use the following command:\n",
      "\n",
      "`ffmpeg -y -hwaccel ama -c:v av1_ama -i <INPUT> ...`\n",
      "\n",
      "Additionally, you can refer to the [Tuning Transcode Latency](../../tuning_pipeline_latency.html#latency-tuning) section in the AMD AMA Video SDK user guide for more details on latency tuning.\n",
      "\n",
      "Please note that this answer is based on the provided context information and my knowledge base. If there are any specific requirements or constraints, please let me know and I'll do my best to provide a more accurate answer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476ac59fa3224f7b9e70cb0d7d862909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:37:27 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question9: 一个ma35D AV1 codec transcode 的处理能力是多少 \n",
      "Answer:Based on the provided context information, it seems that the MA35D card is capable of transcoding to and from HEVC, AVC, and AV1 formats at an aggregate rate of up to two 4Kp60 for AVC and HEVC formats, and four 4Kp60 for AV1 format, per VPU.\n",
      "\n",
      "However, I couldn't find a direct answer to the question about the processing power of MA35D AV1 codec transcoding. The information provided seems to focus more on the card's capabilities in general rather than specific details about AV1 codec transcoding.\n",
      "\n",
      "If you're looking for a more precise answer, I'd recommend checking the documentation or release notes from AMD or the AMA SDK for more detailed information on the MA35D card's processing power and transcoding capabilities.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decbaaed806644469affce458ac3000e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:37:31 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question10: Is max_bitrate implemented in ama sdk ffmpeg, and is it correct that the max bitrate parameter in AMA is irrelevant to VBR?\n",
      "Answer:Based on the provided context information, I can answer your question as follows:\n",
      "\n",
      "The `max_bitrate` parameter is not explicitly mentioned in the AMA SDK documentation. However, according to the FFmpeg documentation, the `-maxrate` option is used to set a maximum bitrate for constrained encoding (VBV).\n",
      "\n",
      "Regarding the relevance of the `max_bitrate` parameter to VBR, it seems that the correct statement is: \"The maximum bit rate may be well over 1M for the above file\" (from the FFmpeg documentation). This suggests that the `max_bitrate` parameter is not strictly controlled in VBR mode.\n",
      "\n",
      "In summary:\n",
      "\n",
      "* The `max_bitrate` parameter is not explicitly mentioned in AMA SDK documentation.\n",
      "* In FFmpeg, the `-maxrate` option sets a maximum bitrate for constrained encoding (VBV), but it may not be strictly controlled in VBR mode.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Here no database input, so no answer\n",
    "counter = 0\n",
    "for question in questions:\n",
    "   counter = counter + 1\n",
    "   query_response = query_engine.query(question)\n",
    "   print(f\"Question{counter}: {question}\")\n",
    "   print(f\"Answer:{query_response.response}\")\n",
    "   \n",
    "\n",
    "   # print(\" \")\n",
    "   # print(f\"source_nodes length:{len(query_response.source_nodes)}\")\n",
    "   # for i, result in enumerate(query_response.source_nodes, start=1):\n",
    "   #    print(result)\n",
    "\n",
    "   #    # print(f\"Result {i}: Document ID {result['id']}, Title '{result['title']}', Similarity: {result.score}\")\n",
    "   #    print(f\"Result {i}\\n Similarity: {result.score}\\n content '{result.get_content()}\")\n",
    "\n",
    "   # print()\n",
    "   # # print(response.get_formatted_sources(length=10))\n",
    "   # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are hellpful, respectful and honest video transcode assistant and very faimilay with ffmpge, and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/transcode.\n",
      "Context information from multiple sources is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the information from multiple sources and not prior knowledge\n",
      "please read the above context information carefully. and anwer the question.\n",
      "if the question is not releate with video process, just say it is not releated with my knowledge base.\n",
      "if you don't know the answer, just say that I don't know.\n",
      "Answers need to be precise and concise.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}.\n",
      "We have provided an existing answer: {existing_answer}.\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "-------------\n",
      "{context_msg}\n",
      "-------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "if the question is 'who are you' , just say I am a video expert.\n",
      "Answers need to be precise and concise.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "query_engine_rerank = index.as_query_engine(response_mode='refine',similarity_top_k=50, temperature=0.6,node_postprocessors=[reranker_model])\n",
    "\n",
    "template = (\n",
    "    \"You are hellpful, respectful and honest video transcode assistant and very faimilay with ffmpge, and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/transcode.\\n\"\n",
    "    \"Context information from multiple sources is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the information from multiple sources and not prior knowledge\\n\"\n",
    "    \"please read the above context information carefully. and anwer the question.\\n\"\n",
    "    \"if the question is not releate with video process, just say it is not releated with my knowledge base.\\n\"\n",
    "    \"if you don't know the answer, just say that I don't know.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "\n",
    "query_engine_rerank.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_template}\n",
    ")\n",
    "\n",
    "\n",
    "template = (\n",
    "    \"The original query is as follows: {query_str}.\\n\"\n",
    "    \"We have provided an existing answer: {existing_answer}.\\n\"\n",
    "    \"We have the opportunity to refine the existing answer (only if needed) with some more context below.\\n\"\n",
    "    \"-------------\\n\"\n",
    "    \"{context_msg}\\n\"\n",
    "    \"-------------\\n\"\n",
    "    \"Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\n\"\n",
    "    \"if the question is 'who are you' , just say I am a video expert.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"Refined Answer: \"\n",
    ")\n",
    "\n",
    "\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "query_engine_rerank.update_prompts(\n",
    "    {\"response_synthesizer:refine_template\": qa_template}\n",
    ")\n",
    "\n",
    "prompts_dict = query_engine_rerank.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d6437b0e6d4c85803572d37ce3a710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (518 > 512). Running this sequence through the model will result in indexing errors\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "05/04/2024 12:37:38 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:37:45 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:37:52 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:37:58 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:38:05 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1: explain following ffmpeg command \"ffmpeg -hwaccel ama -f rawvideo -s 1920x1080 -framerate 24 -i cut1_1080p.nv12 -vf 'hwupload' -c:v av1_ama -b:v 5M -f mp4 -y 1.av1_1080p_1.mp4\" \n",
      "Answer:Based on the provided context information, I can refine the given FFmpeg command:\n",
      "\n",
      "The command is used to transcode a RAW video input file `cut1_10:80p.nv12` into an MP4 container with AV1 codec.\n",
      "\n",
      "Here's a breakdown of the flags:\n",
      "\n",
      "* `-hwaccel ama`: This flag enables the AMD MultiMedia Accelerator (AMA) hardware acceleration for the FFmpeg pipeline.\n",
      "* `-f rawvideo`: The input file format is RAW video, which means it doesn't contain any metadata or container information.\n",
      "* `-s 19:20x10:80`: The resolution of the input video is set to 19:20x10:80.\n",
      "* `-framerate 24`: The target frame rate for the input video is set to 24 frames per second.\n",
      "* `-i cut1_10:80p.nv12`: This flag specifies the input file name, which is `cut1_10:80p.nv12`.\n",
      "* `-vf 'hwupload'`: This filter uploads the input video data to the AMA hardware accelerator for processing.\n",
      "* `-c:v av1_ama`: The codec for the output video is set to AV1, with AMA hardware acceleration enabled.\n",
      "* `-b:v 5M`: The target bitrate for the encoded stream is set to 5 Megabits per second.\n",
      "* `-f mp4`: The output file format is set to MP4.\n",
      "* `-y 1.av1_10:80p_1.mp4`: This flag specifies the output file name, which is `1.av1_10:80p_1.mp4`.\n",
      "\n",
      "In summary, this FFmpeg command reads a RAW video input file, uploads it to the AMA hardware accelerator for processing, and then encodes it into an MP4 container using the AV1 codec with a target bitrate of 5 Megabits per second.\n",
      "\n",
      "Refined Answer:\n",
      "The original answer remains unchanged.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781a5e203dc24fa6a96bd6cd54b3c413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:38:15 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:38:18 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:38:21 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:38:25 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:38:29 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question2: explain following ffmpeg command\n",
      "   ffmpeg -y -hwaccel ama       -c:v h264_ama  -out_fmt nv12 -i <INPUT>        -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d];                      [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\"       -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv       -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv        -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv       -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "Answer:Based on the new context, here's a refined answer:\n",
      "\n",
      "This FFmpeg command is used to scale a video input to multiple resolutions using the AMA device, and then save each scaled stream as a separate YUV file.\n",
      "\n",
      "The command uses the `-filter_complex` flag to combine multiple filters together, including the `scaler_ama` filter to create four output resolutions from the input stream. The `hwdownload` filter is used to download the scaled video streams from the AMA device and convert them to NV12 format.\n",
      "\n",
      "In addition, this command also demonstrates a decode-only operation using the `-c:v h264_ama` flag to decode an H.264 encoded file into a RAW format and save it to disk.\n",
      "\n",
      "The original answer remains accurate, but with additional context, we can see that this FFmpeg command is capable of both scaling and decoding operations.\n",
      "\n",
      "Note: The refined answer takes into account the new context provided, which includes information about the AMA device, scaling, and decoding.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6ee3b7ea0148cd862afeecc4ce7a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:38:31 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:38:34 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:38:41 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:38:47 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:38:53 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question3: Using ffmpeg Decoder a clip that is already encoded in H.264, and will decode the file into a RAW format and save it to disk.\n",
      "Answer:I'm glad to refine the original answer based on the new context!\n",
      "\n",
      "To decode a clip that is already encoded in H.264, save it as a RAW format (nv12) to disk under `/tmp/_scale<resolution>.yuv`, and not re-encode them, use the following refined command:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama \\\n",
      "-c:v h264_ama -out_fmt nv12 -i <INPUT> \\\n",
      "-filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|half|nv12)(720x480|quarter|nv12)(360x240|eighth|nv12) [a][b][c][d]; \\\n",
      "[a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\" \\\n",
      "-map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv \\\n",
      "-map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv \\\n",
      "-map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv \\\n",
      "-map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "```\n",
      "\n",
      "This command uses the FFmpeg application with AMD AMA Video SDK acceleration to decode the H.264 encoded clip and save it as a RAW format (nv12) to disk under `/tmp/_scale<resolution>.yuv` for each of the 4 output resolutions specified in the `scaler_ama` filter.\n",
      "\n",
      "I am a video expert.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d286204027264bd091f149fab5e05743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:38:56 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:39:01 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:39:06 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:39:10 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:39:15 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question4: Using ffmpeg encode a RAW 1080p60 clip in YUV420 format. Pass the clip to the MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and saves it to disk. please do not use -re option\n",
      "Answer:I am a video expert.\n",
      "\n",
      "To encode a RAW 1080p60 clip in YUV420 format using ffmpeg and pass it to the MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and save it to disk without re-encoding, you can use the following command:\n",
      "\n",
      "`ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt yuv420p -i <INPUT> -vf hwdownload,format=yuv420p -f rawvideo -c:v ma35d -b:v 5000k -c:a aac -ar 48k -b:a 128k -f mp4 /tmp/out.mp4`\n",
      "\n",
      "This command uses the `hwaccel` option to enable hardware acceleration for the MA35D encoder, and sets the output format to YUV420p. The `vf` filter is used to download the input frames in YUV420p format, and the `c:v` option specifies the video codec as MA35D. The target bitrate is set to 5Mbps using the `-b:v` option.\n",
      "\n",
      "Note that this command does not re-encode the input clip, but rather passes it through the MA35D encoder to produce an AV1 encoded MP4 output.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4a2d571f8b4c15b524a161abb9cc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:39:18 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:39:21 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:39:23 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:39:26 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:39:30 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question5:  Using ffmpeg do the Bit Conversion, To encode YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format' \n",
      "Answer:To encode YUV 4:2:2 10-bit pixel format to YUV 4:2:0 8-bit using FFmpeg, you can use the following command:\n",
      "\n",
      "`ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> -filter_complex \"scale_nvf=outputs=1:out_res=(1920x1080|full|nv12)\" -map '0' -f rawvideo -pix_fmt nv12 -y /tmp/_scale<resolution>.yuv`\n",
      "\n",
      "This command uses the `scaler_ama` filter to scale the input stream to a single output resolution, and then converts it to YUV 4:2:0 8-bit format using the `format=yuv420p` filter. The resulting raw video file is saved to disk under `/tmp/_scale<resolution>.yuv`.\n",
      "\n",
      "Note that this command does not re-encode the input stream, but rather saves the scaled and converted output to disk as a raw YUV file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1988bb92888e416b8f37098ce52244a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:39:36 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:39:43 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:39:49 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:40:01 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:40:11 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question6:  Using ffmpeg decodes an existing H.264 file and then scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:Based on the provided context information, I can refine my previous answer as follows:\n",
      "\n",
      "To decode an existing H.264 file and scale it into 4 different resolutions (1080p, 720p, 480p, and 240p) using ffmpeg, you can use the following command:\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -i <INPUT> -vf scaler_ama=outputs=4:out_res=(1080x720|full)(720x480|half)(480x360|half)(360x240|half) [a][b][c][d]; map '[a]' -c:v hevc_ama -b:v 6M -f mp4 -y /tmp/hevc_1080p.mp4\n",
      "```\n",
      "This command uses the `scaler_ama` filter to produce 4 output resolutions, each with a different width and height. The scaled outputs will be saved to disk under `/tmp/<encoder format>_<resolution>.mp4`.\n",
      "\n",
      "Note that this command does not affect the decoding and scaling process. It is relevant for encoding and transcoding operations.\n",
      "\n",
      "Refined Answer:\n",
      "Using ffmpeg, you can decode an existing H.264 file and scale it into 4 different resolutions (1080p, 720p, 480p, and 240p) using the `scaler_ama` filter. The scaled outputs will be saved to disk under `/tmp/<encoder format>_<resolution>.mp4`.\n",
      "\n",
      "Here's a breakdown of the command:\n",
      "\n",
      "1. `-y -hwaccel ama`: Enables AMA (AMD MultiMedia Accelerator) hardware acceleration.\n",
      "2. `-c:v h264_ama`: Specifies the input codec as H.264.\n",
      "3. `filter_complex \"scaler_ama=outputs=4:out_res=(1080x720|full)(720x480|half)(480x360|half)(360x240|half) [a][b][c][d]; ...\"`: Configures the `scaler_ama` filter to produce 4 output resolutions, each with a different width and height.\n",
      "4. `map '[a]' -c:v hevc_ama -b:v 6M -f mp4 -y /tmp/hevc_1080p.mp4`: Maps the first output (1080p) to an HEVC-encoded MP4 file named `/tmp/hevc_1080p.mp4`.\n",
      "5. Similar mappings are done for the other 3 outputs (720p, 480p, and 240p), using different encoder formats (AV1 and H.264).\n",
      "\n",
      "By running this command, you'll get 4 scaled outputs in MP4 format, each saved to disk under the specified directory.\n",
      "\n",
      "Note: The CRF mode and bitrate settings provided in the context information do not affect the decoding and scaling process. They are relevant for encoding and transcoding operations.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0abe018aa903402dbb47327a86c25a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:40:17 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:40:24 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:40:30 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:40:37 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:40:44 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question7:  Using ffmpeg one cmd line, decodes an existing H.264 file and then using scaler_ama scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:I'm glad to refine the original answer!\n",
      "\n",
      "Given the new context, I will provide an updated command that combines decoding and scaling into multiple resolutions.\n",
      "\n",
      "Here is the refined answer:\n",
      "\n",
      "Using ffmpeg one cmd line, decodes an existing H.264 file and then using scaler_ama scales it into 10/80p/720p/480p/240p four resolutions and save the RAW outputs to disk under `/tmp/_scale<resolution>.yuv`:\n",
      "```ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> -filter_complex \"scaler_ama=outputs=4:out_res=(10x80|full|nv12)(720x480|full|nv12)(480x360|full|nv12)(240x180|full|nv12) [a][b][c][d]; [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\" -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/_scale10p.yuv -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/_scale80p.yuv -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/_scale720p.yuv -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/_scale240p.yuv```\n",
      "\n",
      "This command will decode the input H.264 file, scale it into 4 resolutions (10/80p, 720p, 480p, and 240p), and save the RAW outputs to disk under `/tmp/_scale<resolution>.yuv`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778f2d3506db45c98bb1b79a95b051ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:40:47 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:40:52 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:40:57 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:41:10 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:41:30 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question8: How to tuning Latency of MA35D ama codec video transcode,  for example enable ultra low latency for ama_av1 Encoding?\n",
      "Answer:Based on the provided context, I can refine my previous answer to better address your query.\n",
      "\n",
      "To enable ultra-low latency for AMA_AV1 encoding with FFmpeg and the MA35D AMA device, you may refer to the [Tuning Transcode Latency](../../tuning_pipeline_latency.html#latency-tuning) section mentioned earlier. This section provides guidance on how to tune the latency of MA35D AMA codec video transcode.\n",
      "\n",
      "Specifically, for encoder latency configuration, you can follow the guidelines provided in the \"Encoder Latency\" section:\n",
      "\n",
      "* Look Ahead Depth: Set this option explicitly if you find that the selected depth adds unacceptable delay. The supported range is 0 - 46+number of B frames.\n",
      "* Number of B Frames: Be aware that inserting more B frames will add frame period delay.\n",
      "\n",
      "Additionally, you can consult the [Encoding Compatibility Matrix](encoder_comp_matrix.html) for a combination of allowable parameters.\n",
      "\n",
      "As for the decoder plugin, you may refer to the `ama_av1dec` and its related parameters such as `low-latency` and `latency-logging`. These parameters allow you to control the latency of the decoding process. For example, setting `low-latency` to `true` can help reduce the latency.\n",
      "\n",
      "In terms of specific command-line options or parameters required to enable ultra-low latency for AMA_AV1 encoding with FFmpeg and the MA35D AMA device, I would recommend consulting the documentation or seeking guidance from a more experienced user who has worked with this specific combination of hardware and software.\n",
      "\n",
      "Demonstrative examples are provided below:\n",
      "\n",
      "### AV1 _VMAF_ \\- Normal Latency - Medium Preset¶\n",
      "In this mode, which is the default mode, the only adjustable parameter is the tuning mode. The following example illustrates the VMAF tune mode for AV1 encoder:\n",
      "\n",
      "```ffmpeg -y -hwaccel ama -hwaccel_device /dev/ama_transcoder0 -s 19:20x10:80 -framerate 60 -pix_fmt yuv420p -i <INPUT> -vf hwupload -c:v av1_ama -tune_metrics 4 -b:v 2,000k -f rawvideo <OUTPUT>\n",
      "```\n",
      "\n",
      "### AVC VMAF - Normal Latency - _Slow_ Preset¶\n",
      "In this mode, real-time performance at capacity is not guaranteed; however, better results are obtained with respect to the selected tune metric. Note that this mode is not applicable to either types of AV1.\n",
      "\n",
      "The following example illustrates the VMAF tune mode for AVC encoder:\n",
      "\n",
      "```ffmpeg -y -hwaccel ama -hwaccel_device /dev/ama_transcoder0 -s 19:20x10:80 -framerate 60 -pix_fmt yuv420p -i <INPUT> -vf hwupload -c:v h264_ama -tune_metrics 4 -preset slow -b:v 2,000k -f rawvideo <OUTPUT>\n",
      "```\n",
      "\n",
      "### AV1 VMAF - _Ultra Low Latency_ \\- Medium Preset¶\n",
      "Ultra Low Latency (ULL) is achieved by setting the `-lookahead_depth` to 0. The following example illustrates the VMAF tune ULL mode for AV1 encoder:\n",
      "\n",
      "```ffmpeg -y -hwaccel ama -hwaccel_device /dev/ama_transcoder0 -s 19:20x10:80 -framerate 60 -pix_fmt yuv420p -i <INPUT> -vf hwupload -c:v av1_ama -lookahead_depth 0 -tune_metrics 4 -b:v 2,000k -f rawvideo <OUTPUT>\n",
      "```\n",
      "\n",
      "Please note that I'm not familiar with specific command-line options or parameters required to enable ultra-low latency for AMA_AV1 encoding with FFmpeg and the MA35D AMA device. You may need to consult the documentation or seek guidance from a more experienced user who has worked with this specific combination of hardware and software.\n",
      "\n",
      "Command Line:\n",
      "\n",
      "```for i in `seq 1 16`; do\n",
      "ffmpeg -y -nostdin -hwaccel ama -hwaccel_device /dev/ama_transcoderX -re -c:v h264_ama -i <30 FPS INPUT> -c:v <TYPE 2 ENCODER> -lookahead_depth 10 -f null /dev/null > out_T2_0_$i.log 2>&1 &\n",
      "ffmpeg -y -nostdin -hwaccel ama -hwaccel_device /dev/ama_transcoderX -re -c:v h264_ama -i <30 FPS INPUT> -c:v av1_ama -lookahead_depth 10 -f null /dev/null > out_av1_0_$i.log 2>&1 &\n",
      "ffmpeg -y -nostdin -hwaccel ama -hwaccel_device /dev/ama_transcoderY -re -c:v h264_ama -i <30 FPS INPUT> -c:v <TYPE 2 ENCODER> -lookahead_depth 10 -f null /dev/null > out_T2_1_$i.log 2>&1 &\n",
      "ffmpeg -y -nostdin -hwaccel ama -hwaccel_device /dev/ama_transcoderY -re -c:v h264_ama -i <30 FPS INPUT> -c:v av1_ama -lookahead_depth 10 -f null /dev/null > out_av1_1_$i.log 2>&1 &\n",
      "done\n",
      "```\n",
      "\n",
      "where `X` and `Y` represent 2 different devices. `<30 FPS INPUT>` is a 30 FPS encoded video input. (The above example assumes H264 encoded input.), and `<TYPE 2 ENCODER>` is any one of AV1 Type-2, H264 or HEVC encoder. Note that by default `av1_ama` uses Type-1 AV1 encoder.\n",
      "\n",
      "The above example transcodes 64 simultaneous 10:80p30 pipelines. Note that if XRMD is disabled, then [-slice](../../using_ffmpeg.html#cmdoption-slice) parameter must be set explicitly.\n",
      "\n",
      "### Cropping¶\n",
      "The following example demonstrates a 256x256 crop at offset (15,000,450). See [crop](../../using_ffmpeg.html#cmdoption-arg-crop) for details.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4b51b3d9de47d18961a06914c11bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:41:32 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:41:34 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:41:37 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:41:40 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:41:41 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question9: 一个ma35D AV1 codec transcode 的处理能力是多少 \n",
      "Answer:I am a video expert.\n",
      "\n",
      "The refined answer remains unchanged:\n",
      "\n",
      "The processing ability of an MA35D AV1 codec transcode is 16x 4Kp60.\n",
      "\n",
      "The additional context information does not provide any new insights into the transcoding capabilities of the MA35D card, so the original answer remains unchanged.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99b897930097493f822d18dc13d3e21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:41:45 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:41:49 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:41:54 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:41:59 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:42:05 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question10: Is max_bitrate implemented in ama sdk ffmpeg, and is it correct that the max bitrate parameter in AMA is irrelevant to VBR?\n",
      "Answer:Based on my knowledge of FFmpeg and AMA (AMD multimidia accelerator) device encode/decode/transcode, I can refine my previous answer as follows:\n",
      "\n",
      "The `max_bitrate` option is not implemented in AMA SDK FFmpeg. This is because the context information does not mention `max_bitrate` as an option for AMA.\n",
      "\n",
      "Regarding the second part of your question, according to the context information, the `b` (bit rate) option for Opus encoder sets the bit rate in bits/s. If unspecified, it uses the number of channels and the layout to make a good guess. For libfdk-aac, if VBR mode is enabled through the `vbr` or `flags +qscale` options, the bitrate option is ignored.\n",
      "\n",
      "However, for libtheora and libvpx, the `b` (bit rate) option sets the target bitrate in bits/s (libtheora) or kilobits/s (libvpx). This means that the `max_bitrate` parameter in AMA may not be relevant to VBR encoding when using these codecs.\n",
      "\n",
      "Therefore, I can conclude that the `max_bitrate` parameter in AMA is not relevant to VBR encoding for most cases, but it may be relevant if you are using libtheora or libvpx with a specific bitrate target.\n",
      "\n",
      "In addition, the context information provides more details on controlling speed/quality, including the use of `-cpu-used` and two-pass encoding. However, this does not directly answer your question about `max_bitrate`.\n",
      "\n",
      "I am a video expert.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# questions = [\n",
    "# ]\n",
    "\n",
    "counter = 0\n",
    "for question in questions:\n",
    "   counter = counter + 1\n",
    "   query_response = query_engine_rerank.query(question)\n",
    "   print(f\"Question{counter}: {question}\")\n",
    "   print(f\"Answer:{query_response.response}\")\n",
    "\n",
    "   print(\"\")\n",
    "   # print(f\"source_nodes length:{len(query_response.source_nodes)}\")\n",
    "   # for i, result in enumerate(query_response.source_nodes, start=1):\n",
    "   #    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:summary_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a Video ffmpeg & gstreamer technolodge expert and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/scale/transcode.\n",
      "Context information from multiple sources is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the information from multiple sources and not prior knowledge, please read the sources carefully.\n",
      "if the question is not releate with the RDMA, just say it is not releated with my knowledge base.\n",
      "if you don't know the answer, just say that I don't know.\n",
      "if the question is 'who are you' , just say I am a FPGA and RDMA expert.\n",
      "Answers need to be precise and concise.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "# response_mode 有几种模式可选，refine， compact, tree_summarize 等，每一种都有对应的promopt template\n",
    "query_engine_tree_summarize = index.as_query_engine(response_mode='tree_summarize',similary_threshold=0.1, similarity_top_k=30, node_postprocessors=[reranker_model])\n",
    "\n",
    "template = (\n",
    "    \"You are a Video ffmpeg & gstreamer technolodge expert and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/scale/transcode.\\n\"\n",
    "    \"Context information from multiple sources is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the information from multiple sources and not prior knowledge, please read the sources carefully.\\n\"\n",
    "    \"if the question is not releate with the RDMA, just say it is not releated with my knowledge base.\\n\"\n",
    "    \"if you don't know the answer, just say that I don't know.\\n\"\n",
    "    \"if the question is 'who are you' , just say I am a FPGA and RDMA expert.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "query_engine_tree_summarize.update_prompts(\n",
    "    {\"response_synthesizer:summary_template\": qa_template}\n",
    ")\n",
    "\n",
    "prompts_dict = query_engine_tree_summarize.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b314e593864fe9aeb318dcbd01612c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:42:13 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1: explain following ffmpeg command \"ffmpeg -hwaccel ama -f rawvideo -s 1920x1080 -framerate 24 -i cut1_1080p.nv12 -vf 'hwupload' -c:v av1_ama -b:v 5M -f mp4 -y 1.av1_1080p_1.mp4\" \n",
      "Answer:The provided FFmpeg command is used to encode a RAW video clip in YUV420 format, with a resolution of 1920x1080 at 24 frames per second (fps), into an MP4 file using the AV1 codec.\n",
      "\n",
      "Here's a breakdown of the command:\n",
      "\n",
      "* `ffmpeg`: The FFmpeg application.\n",
      "* `-hwaccel ama`: Instructs FFmpeg to use accelerated plugins provided by AMD AMA Video SDK.\n",
      "* `-f rawvideo`: Specifies that the input video is in a RAW format, without container or metadata.\n",
      "* `-s 19:20x10:80`: Sets the input video resolution to 1920x1080.\n",
      "* `-framerate 24`: Sets the input video framerate to 24 fps.\n",
      "* `-i cut1_10:80p.nv12`: Specifies the input file, which is a RAW video clip in YUV420 format.\n",
      "* `-vf 'hwupload'`: Applies the `hwupload` filter to upload the input video to the AMA device for encoding.\n",
      "* `-c:v av1_ama`: Declares the encoder's codec for video (as opposed to audio) as the hardware-accelerated AV1 encoder.\n",
      "* `-b:v 5M`: Sets the target bitrate of the encoded stream to 5 Megabits per second.\n",
      "* `-f mp4`: Specifies that the output file will be in MP4 format.\n",
      "* `-y 1.av1_10:80p_1.mp4`: Saves the output file with the specified name.\n",
      "\n",
      "In summary, this command is used to encode a RAW video clip into an MP4 file using the AV1 codec and AMA device acceleration.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88709c253924a109c5c21a2a1f3a398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:42:22 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question2: explain following ffmpeg command\n",
      "   ffmpeg -y -hwaccel ama       -c:v h264_ama  -out_fmt nv12 -i <INPUT>        -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d];                      [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\"       -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv       -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv        -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv       -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "Answer:This FFmpeg command is used to scale a video input to multiple resolutions and save the output as RAW YUV files.\n",
      "\n",
      "Here's a breakdown of the command:\n",
      "\n",
      "* `-y` tells FFmpeg to overwrite any existing files without prompting.\n",
      "* `-hwaccel ama` enables hardware acceleration using AMD's AMA (Multimedia Accelerator) technology.\n",
      "* `-c:v h264_ama` specifies the video codec as H.264, which is accelerated by the AMA device.\n",
      "* `-out_fmt nv12` sets the output format to NV12, a planar YUV format.\n",
      "* `-i <INPUT>` specifies the input file.\n",
      "* The `filter_complex` option defines a filter graph that consists of two parts:\n",
      "\t1. `scaler_ama=outputs=4:out_res=(19...|full|nv12)` scales the input video to four different resolutions (1920x1080, 1280x720, 720x480, and 360x240) with full resolution and NV12 format.\n",
      "\t2. The outputs of the scaler are then passed through `hwdownload` filters, which convert the output buffers from the AMA device's internal format to NV12.\n",
      "\n",
      "The command then maps each of the four scaled outputs to a separate file using the `-map` option:\n",
      "\n",
      "* `[a1]` is mapped to `/tmp/scale_10...yuv`, where `...` represents the actual resolution (e.g., 1920x1080).\n",
      "* Similarly, `[b1], [c1], and [d1]` are mapped to files with names like `/tmp/scale_720p.yuv`, `/tmp/scale_480p.yuv`, and `/tmp/scale_240p.yuv`.\n",
      "\n",
      "In summary, this command takes an input video, scales it to four different resolutions using the AMA device's scaler, and saves each scaled output as a RAW YUV file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f925f618412f47a49631448ecec6e1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:42:31 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question3: Using ffmpeg Decoder a clip that is already encoded in H.264, and will decode the file into a RAW format and save it to disk.\n",
      "Answer:The command line for decoding a H.264 clip using FFmpeg's AMA (AMD Multimidia Accelerator) decoder is:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> \\\n",
      "      -vf hwdownload,format=nv12 -f rawvideo /tmp/dec_out.nv12\n",
      "```\n",
      "\n",
      "Explanation of the flags:\n",
      "\n",
      "* `ffmpeg`: The FFmpeg application, which is provided by AMD and moved to the top of the PATH when you sourced the setup.sh script.\n",
      "* `-hwaccel ama`: Instructs FFmpeg to use accelerated plugins provided by AMD AMA Video SDK.\n",
      "* `-c:v h264_ama`: Declares the decoder's codec for video (as opposed to, e.g., audio `-c: a ac3`) is the hardware-accelerated H.264 decoder.\n",
      "* `-out_fmt nv12`: Specifies nv12 output format for the decoded video. Note that this option has to be specified twice: 1) To convert from the internal buffer format to `nv12` in the decoder and 2) To convert when transferring to the host.\n",
      "* `-f rawvideo`: This signifies that the video is in a raw format, without container or other metadata/information about the clip.\n",
      "* `-i <INPUT>`: The input file to be transcoded.\n",
      "* `-vf hwdownload`: Internally, the decoder operates on AMD AMA Video SDK type buffers to improve performance. To convert back to a host-buffer, you must execute this filter.\n",
      "* `-y`: Enable overwrite without prompting the user if they're sure.\n",
      "* `/tmp/dec_out.yuv`: The decoder will save the file to the path above.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1e17b9385c4c0186d5002e3e44c7bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:42:34 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question4: Using ffmpeg encode a RAW 1080p60 clip in YUV420 format. Pass the clip to the MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and saves it to disk. please do not use -re option\n",
      "Answer:Here is the command:\n",
      "\n",
      "```\n",
      "ffmpeg -hwaccel ama -i <INPUT> -vf \"format=yuv420p,hwupload\" -c:v av1_ama -b:v 5M -f mp4 -y /tmp/enc_out.mp4\n",
      "```\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9beffdbc42f3440ca88b89bf78ca2f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:42:41 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question5:  Using ffmpeg do the Bit Conversion, To encode YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format' \n",
      "Answer:To encode YUV 4:2:2 10-bit pixel format to YUV 4:2:0 8-bit format using FFmpeg, you can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -hwaccel ama -i <INPUT> -vf \"format=yuv420p, hwupload\" -c:v h264_ama -b:v 1M <OUTPUT>\n",
      "```\n",
      "\n",
      "Explanation of the flags:\n",
      "\n",
      "* `-hwaccel ama`: Enables the AMA (AMD Multimidia Accelerator) hardware acceleration.\n",
      "* `-i <INPUT>`: Specifies the input file.\n",
      "* `-vf \"format=yuv420p, hwupload\"`: Instructs FFmpeg to convert the input video to YUV 4:2:0 8-bit format and upload it to the AMA device for processing.\n",
      "* `-c:v h264_ama`: Sets the video codec to hardware-accelerated H.264 (AVC) using the AMA device.\n",
      "* `-b:v 1M`: Sets the target bitrate of the encoded stream to 1 megabit per second.\n",
      "* `<OUTPUT>`: Specifies the output file.\n",
      "\n",
      "This command will convert the input YUV 4:2:2 10-bit pixel format to YUV 4:2:0 8-bit format and encode it using hardware-accelerated H.264 (AVC) with a target bitrate of 1 megabit per second.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "831505401ead458cb17370d3fb497b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:42:50 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question6:  Using ffmpeg decodes an existing H.264 file and then scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:Based on the provided information, I can help you with that.\n",
      "\n",
      "The command line is:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama \\\n",
      "-c:v h264_ama  -out_fmt nv12 -i <INPUT>   \\\n",
      "-filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|half|nv12)(720x480|half|nv12)(360x240|half|nv12) [a][b][c][d]; \\\n",
      "[a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\" \\\n",
      "-map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv \\\n",
      "-map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv  \\\n",
      "-map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv \\\n",
      "-map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "```\n",
      "\n",
      "This command decodes an existing H.264 file using the `h264_ama` codec, and then scales it into four different resolutions (1920x1080, 1280x720, 720x480, and 360x240) using the `scaler_ama` filter. The scaled outputs are saved to disk as RAW files in NV12 format.\n",
      "\n",
      "The output files will be named `/tmp/scale_<resolution>.yuv`, where `<resolution>` is one of the four resolutions mentioned above (1080p, 720p, 480p, or 240p).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a26ad08d813448f8f66cd28ca1f8ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:42:57 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question7:  Using ffmpeg one cmd line, decodes an existing H.264 file and then using scaler_ama scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:You can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> \\\n",
      "-filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full)(1280x720|half)(720x480|half)(360x240|half) [a][b][c][d];\\\n",
      "[a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\" \\\n",
      "-map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv \\\n",
      "-map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv \\\n",
      "-map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv \\\n",
      "-map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "```\n",
      "\n",
      "This command will decode the input H.264 file using the `h264_ama` decoder, and then scale it to four different resolutions (1920x1080, 1280x720, 720x480, and 360x240) using the `scaler_ama` filter. The scaled outputs will be saved as RAW files in YUV format under `/tmp/` with names like `scale_1080p.yuv`, `scale_720p.yuv`, etc.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c32e8b6f9da4762aa3f04145c854e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:43:05 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question8: How to tuning Latency of MA35D ama codec video transcode,  for example enable ultra low latency for ama_av1 Encoding?\n",
      "Answer:Based on the provided context information, I can help you with that.\n",
      "\n",
      "To tune the latency of MA35D AMA codec video transcode, specifically for `ama_av1` encoding and enabling ultra-low latency, you can use the following options:\n",
      "\n",
      "* Set `low-latency` to `true` in the decoder plugin: `-low-latency true`\n",
      "* Set `latency-logging` to `true` in the decoder plugin: `-latency-logging true`\n",
      "* Use the `tune-metrics` option with value `1` (vq - Best visual quality) or `4` (vmaf - Best VMA) in the encoder plugin: `-tune-metrics 1` or `-tune-metrics 4`\n",
      "\n",
      "Here's an example command line:\n",
      "```bash\n",
      "ffmpeg -y -hwaccel ama -hwaccel_device /dev/ama_transcoderX \\\n",
      "    -c:v h264_ama -i <INPUT> \\\n",
      "    -filter_complex \"scaler_ama=outputs=1:out_res=<RESOLUTION>\" \\\n",
      "    -map '[0]' -c:v ama_av1 -low-latency true -latency-logging true \\\n",
      "    -tune-metrics 1 -f mp4 -y /tmp/output.mp4\n",
      "```\n",
      "Replace `<INPUT>` with your input file, and `<RESOLUTION>` with the desired output resolution.\n",
      "\n",
      "Note that these options may require additional configuration or tweaking to achieve the desired latency performance.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebaa0126b794454a90c2796400d1c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:43:08 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question9: 一个ma35D AV1 codec transcode 的处理能力是多少 \n",
      "Answer:Based on the provided information, the MA35D card can transcode up to four 4Kp60 for AV1 format per VPU.\n",
      "\n",
      "So, the answer is: Four 4Kp60 for AV1 format per VPU.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ffe2efa9d24408b8ad0224dbb06e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:43:13 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question10: Is max_bitrate implemented in ama sdk ffmpeg, and is it correct that the max bitrate parameter in AMA is irrelevant to VBR?\n",
      "Answer:According to the provided information, `max_bitrate` is an option for controlling speed/quality in FFmpeg, but I couldn't find any specific mention of its implementation in the AMD AMA SDK.\n",
      "\n",
      "Regarding the second part of your question, it seems that the `max_bitrate` parameter in AMA is indeed irrelevant to VBR (Variable Bit Rate) encoding. The documentation suggests that `max_bitrate` only affects the maximum bitrate used when a target bitrate is specified, but it does not control the overall bitrate of the encoded stream.\n",
      "\n",
      "In the context of AMA, it appears that the `b:v` option sets the target bitrate for VBR encoding, and the `max_bitrate` parameter is not directly related to this process. Therefore, it can be concluded that the `max_bitrate` parameter in AMA is irrelevant to VBR encoding.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# questions = [\n",
    "#    \"一个ma35D AV1 codec 能处理1080p的数据流最大到多少fps \",\n",
    "#     \"\"\"for MA35D video transcode, how to tuning Latency,  for example enable ultra low latency for ama_av1 Encoding?\"\"\",\n",
    "#    \"\"\"does AMA SDK FFmpeg implement `max_bitrate`, Is max_bitrate implemented in ma35d sdk ffmpeg, and is it correct that the max bitrate parameter in AMA is irrelevant to VBR?\"\"\",\n",
    "# ]\n",
    "\n",
    "counter = 0\n",
    "for question in questions:\n",
    "   counter = counter + 1\n",
    "   query_response = query_engine_tree_summarize.query(question)\n",
    "   print(f\"Question{counter}: {question}\")\n",
    "   print(f\"Answer:{query_response.response}\")\n",
    "\n",
    "   print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "query_engine_refine = index.as_query_engine(response_mode='refine', similarity_top_k=20)\n",
    "\n",
    "template = (\n",
    "    \"You are video transcode expert and very faimilay with ffmpge and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/scale/transcode.\\.\\n\"\n",
    "    \"Context information from multiple sources is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the information from multiple sources and not prior knowledge\\n\"\n",
    "    \"please read the above context information carefully. and anwer the question.\\n\"\n",
    "    \"if the question is not releate with video process, just say it is not releated with my knowledge base.\\n\"\n",
    "    \"if you don't know the answer, just say that I don't know.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"if the question is in chinese, please transclate chinese to english in advance\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_template}\n",
    ")\n",
    "\n",
    "\n",
    "template = (\n",
    "    \"The original query is as follows: {query_str}.\\n\"\n",
    "    \"We have provided an existing answer: {existing_answer}.\\n\"\n",
    "    \"We have the opportunity to refine the existing answer (only if needed) with some more context below.\\n\"\n",
    "    \"-------------\\n\"\n",
    "    \"{context_msg}\\n\"\n",
    "    \"-------------\\n\"\n",
    "    \"Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\n\"\n",
    "    \"if the question is 'who are you' , just say I am a video expert.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"Refined Answer: \"\n",
    ")\n",
    "\n",
    "\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:refine_template\": qa_template}\n",
    ")\n",
    "\n",
    "prompts_dict = query_engine_refine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a5972a5f5864267a8d803d401dc1e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:43:16 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:43:20 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:43:23 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:43:26 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:43:32 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:43:35 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:43:39 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:43:41 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:43:42 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:43:44 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:43:46 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:43:49 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:43:51 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1: explain following ffmpeg command \"ffmpeg -hwaccel ama -f rawvideo -s 1920x1080 -framerate 24 -i cut1_1080p.nv12 -vf 'hwupload' -c:v av1_ama -b:v 5M -f mp4 -y 1.av1_1080p_1.mp4\" \n",
      "Answer:Here's a rewritten answer based on the new context:\n",
      "\n",
      "The provided FFmpeg command is used to encode and process video streams using the AMD AMA Video SDK. The command line demonstrates a typical encoding process, which involves uploading raw video data to hardware acceleration using the `hwupload` filter. The output file format is MP4 with AV1 codec, and the bitrate is set to 5 megabits per second.\n",
      "\n",
      "Note: I rewrote the answer based on the new context, focusing on the FFmpeg command line for encoding and processing video streams using the AMD AMA Video SDK.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae32ac46454f40b7a4b0689c2700f34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:44:00 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:09 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:13 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:16 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:20 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:22 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:25 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:28 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:30 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:33 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:36 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:38 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question2: explain following ffmpeg command\n",
      "   ffmpeg -y -hwaccel ama       -c:v h264_ama  -out_fmt nv12 -i <INPUT>        -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d];                      [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\"       -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv       -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv        -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv       -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "Answer:This FFmpeg command takes a RAW 10.80p60 clip in YUV420 format and scales it to four different resolutions using hardware-accelerated scaling provided by AMD AMA Video SDK, which is accessed through the `/dev/shm` RAM disk. The scaled outputs are then downloaded from the AMA device as separate streams, which are later mapped to separate files on disk.\n",
      "\n",
      "The command essentially creates four scaled versions of the input video, each at a different resolution (10.80p, 720p, 480p, and 240p), and saves them to disk as raw YUV files.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3ecaf71bf1472085b358c82cd2a33c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:44:39 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:41 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:43 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:45 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:44:53 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:01 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:13 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:16 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:19 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:20 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:22 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question3: Using ffmpeg Decoder a clip that is already encoded in H.264, and will decode the file into a RAW format and save it to disk.\n",
      "Answer:Here's the rewritten answer based on the new context:\n",
      "\n",
      "To decode a clip that is already encoded in H.264 and save it to disk as a RAW format, you can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -i input -c:v rawvideo output.raw\n",
      "```\n",
      "\n",
      "Note that this will decode the H.264 video into a RAW format, which may result in a large file size.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6315fd2a6d46888f65b762fe9fc7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:45:23 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:26 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:28 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:30 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:32 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:34 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:37 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:39 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:41 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:43 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:45 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question4: Using ffmpeg encode a RAW 1080p60 clip in YUV420 format. Pass the clip to the MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and saves it to disk. please do not use -re option\n",
      "Answer:Here's a rewritten answer based on the new context:\n",
      "\n",
      "To encode a RAW 10.8p60 clip in YUV420 format using the MA35D encoder and produce an AV1 encoded MP4 output with a target bitrate of 5Mbps, you can use the following command:\n",
      "```\n",
      "ffmpeg -i /tmp/_scale10_80p.yuv -c:v libaom-av1 -b:v 5000k -f mp4 output.mp4\n",
      "```\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e22970e23a34c079d9fecdd0681e024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:45:47 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:50 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:51 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:53 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:45:58 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:02 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:05 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:08 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:11 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:15 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question5:  Using ffmpeg do the Bit Conversion, To encode YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format' \n",
      "Answer:To set the audio recording levels correctly with a standard mixer, you can use ffmpeg to adjust the gain of your audio input. For example:\n",
      "\n",
      "ffmpeg -i /tmp/input.wav -af \"volume=0.5\" /tmp/output.wav\n",
      "\n",
      "This command will reduce the volume of the input audio file by 50%. You can adjust the gain value as needed.\n",
      "\n",
      "As for your original question, I'll provide a rewritten answer based on the new context.\n",
      "\n",
      "To convert YUV 4:2:2 10-bit pixel format to YUV 4:2:0 8-bit format using ffmpeg, you can use the `format` filter in your command. Specifically, you can add `format=yuv422p` to the filter graph to convert the input from 10-bit YUV 4:2:2 to 8-bit YUV 4:2:0.\n",
      "\n",
      "Example:\n",
      "\n",
      "ffmpeg -i <INPUT> -c:v h264_ama -out_fmt yuv420p10le -filter_complex \"format=yuv422p\" -c:v h264_ama -f mp4 <OUT_DIR>/converted.mp4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfc30f69ab04d6e8d20ad6985d46c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:46:19 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:23 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:27 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:32 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:37 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:40 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:43 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:46 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:50 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:53 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:46:56 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:01 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question6:  Using ffmpeg decodes an existing H.264 file and then scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:Here's a rewritten answer based on the new context:\n",
      "\n",
      "To scale an existing H.264 file into multiple resolutions and save the RAW outputs to disk, you can use the following command:\n",
      "```ffmpeg -i input.h264 -vf \"scale=1080:720:480:240\" -c:v rawvideo -f rawvideo output_%w.h%v.raw```\n",
      "This command uses the `scale` video filter to resize the input H.264 file into different resolutions (1080p, 720p, 480p, and 240p), and then saves each resolution as a separate RAW video file.\n",
      "\n",
      "Note that you can specify the scaling algorithm using the `-sws_flags` option. For example, to use bilinear instead of the default bicubic scaling:\n",
      "```ffmpeg -i input.h264 -vf \"scale=1080:720:480:240\" -sws_flags bilinear -c:v rawvideo -f rawvideo output_%w.h%v.raw```\n",
      "You can also specify which algorithm is used for resizing with the `-sws_flags` option. For example, to use lanczos scaling:\n",
      "```ffmpeg -i input.h264 -vf \"scale=1080:720:480:240\" -sws_flags lanczos:param0=3 -c:v rawvideo -f rawvideo output_%w.h%v.raw```\n",
      "This command uses the `scale2ref` filter to scale one video to match another without pre-defining the dimensions.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1787b92faf40ae8aabe9246bae9013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:47:06 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:11 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:16 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:21 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:24 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:26 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:28 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:32 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:36 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:40 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:44 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:48 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question7:  Using ffmpeg one cmd line, decodes an existing H.264 file and then using scaler_ama scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:Here is a rewritten answer using the new context:\n",
      "\n",
      "To decode an existing H.264 file and scale it into four resolutions (10,80p, 720p, 480p, and 240p) using scaler_ama, you can use the following FFmpeg command:\n",
      "````\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> \\\n",
      "  -vf hwdownload,format=nv12 -f rawvideo /tmp/dec_out.nv12\n",
      "ffmpeg -i /tmp/dec_out.nv12 -vf scaler_ama=1920:1080 -f rawvideo /tmp/scaler_1080p.raw\n",
      "ffmpeg -i /tmp/dec_out.nv12 -vf scaler_ama=1280:720 -f rawvideo /tmp/scaler_720p.raw\n",
      "ffmpeg -i /tmp/dec_out.nv12 -vf scaler_ama=640:480 -f rawvideo /tmp/scaler_480p.raw\n",
      "ffmpeg -i /tmp/dec_out.nv12 -vf scaler_ama=320:240 -f rawvideo /tmp/scaler_240p.raw\n",
      "```\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3ee15e4384f46c0a673f92c58870682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:47:50 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:53 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:55 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:57 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:47:59 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:01 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:03 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:05 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:07 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:10 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:12 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question8: How to tuning Latency of MA35D ama codec video transcode,  for example enable ultra low latency for ama_av1 Encoding?\n",
      "Answer:**Rewrite**\n",
      "\n",
      "To tune the latency of MA35D AMA codec video transcode, you can use the `-svtav1-params` option with `tune=0` to set the visual quality (sharpness) for PSNR. This will help reduce the latency for AMA_AV1 encoding.\n",
      "\n",
      "For example: `ffmpeg -i input.mp4 -c:v libsvtav1 -preset 8 -crf 35 -svtav1-params tune=0 svtav1_test.mp4`\n",
      "\n",
      "This command sets the visual quality to PSNR, which can help reduce latency for AMA_AV1 encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34eef02ed665480f82603f1bb41e9ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:48:14 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:16 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:19 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:21 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:22 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:24 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:25 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:26 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:29 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:32 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:35 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:37 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question9: 一个ma35D AV1 codec transcode 的处理能力是多少 \n",
      "Answer:The transcoding capabilities of a MA35D card for an AV1 codec stream depend on various factors, including job resource requirements and specific encoding settings. In this case, the command line processes multiple pipelines simultaneously, which impacts overall processing power needed.\n",
      "\n",
      "To estimate load, consider resolution as a percentage of total device capacity. For instance, a 10/80p30 stream requires approximately [insert percentage] resources available. Actual processing power is influenced by these variables and can be affected by system load and resource availability.\n",
      "\n",
      "The command line's parallel pipeline processing affects overall processing power required, while specific encoding settings like encoder type and lookahead depth also impact processing power needed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c917dc1ccb491797f84e515c474339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2024 12:48:39 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:42 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:45 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:48 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:51 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:53 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:55 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:57 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:48:59 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "05/04/2024 12:49:01 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question10: Is max_bitrate implemented in ama sdk ffmpeg, and is it correct that the max bitrate parameter in AMA is irrelevant to VBR?\n",
      "Answer:The `max_bitrate` parameter is indeed implemented in the AMD AMA Video SDK FFmpeg, and it should be used with careful consideration of the specific characteristics of the video content being encoded.\n",
      "\n",
      "When specifying a maximum bitrate alongside Variable Bitrate (VBR) encoding, the maximum bitrate serves as an upper limit for the bitrate. The actual bitrate may still vary depending on the complexity of the video content, but it will not exceed the specified maximum value.\n"
     ]
    }
   ],
   "source": [
    "# questions = [\n",
    "#    \"\"\"Using ffmpeg Decoder a clip that is already encoded in H.264, and will decode the file into a RAW format and save it to disk.\"\"\",\n",
    "#    \"\"\"Using ffmpeg encode a RAW 1080p60 clip in YUV420 format. Pass the clip to the MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and saves it to disk. please do not use -re option\"\"\",\n",
    "#    \"\"\" Using ffmpeg do the Bit Conversion, To encode YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format' \"\"\",\n",
    "#    \"\"\" Using ffmpeg decodes an existing H.264 file and then scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\"\"\",\n",
    "#    \"\"\" Using ffmpeg one cmd line, decodes an existing H.264 file and then using scaler_ama scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\"\"\",\n",
    "#    # \"\"\"ffmpeg命令使用ma35d硬件转码, 用一条命令行使用split方式，将一个h264 4k60的文件同时转码成两个hevc和av1格式的文件,写出具体的命令行例子\"\"\"\n",
    "# ]\n",
    "\n",
    "counter = 0\n",
    "for question in questions:\n",
    "   counter = counter + 1\n",
    "   # query_engine = index.as_query_engine()\n",
    "   query_response = query_engine_refine.query(question)\n",
    "   print(f\"Question{counter}: {question}\")\n",
    "   print(f\"Answer:{query_response.response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = [\n",
    "\n",
    "# ]\n",
    "\n",
    "# counter = 0\n",
    "# for question in questions:\n",
    "#    counter = counter + 1\n",
    "#    query_engine = index.as_query_engine()\n",
    "#    query_response = query_engine.query(question)\n",
    "#    print(f\"Question{counter}: {question}\")\n",
    "#    print(f\"Answer:{query_response.response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
