{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# # LLamaIndex 使用 PyTorch 进行向量计算\n",
    "# # 清理GPU 资源\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # 垃圾回收\n",
    "# import gc\n",
    "# gc.collect()\n",
    "\n",
    " # --can not run in notebook, run it in cmdline\n",
    "# ! nvidia-smi --gpu-reset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 数量： 2\n",
      "GPU 0: Tesla V100-PCIE-16GB，内存使用情况：930.5625 MB / 16384.0 MB\n",
      "GPU 1: Tesla V100-PCIE-16GB，内存使用情况：930.5625 MB / 16384.0 MB\n",
      "当前系统内存使用信息 pmem(rss=77815808, vms=720183296, shared=16703488, text=2818048, lib=0, data=148164608, dirty=0)\n",
      "物理内存中实际驻留的大小 0.07247161865234375 GB\n",
      "虚拟内存的大小，包括实际使用的物理内存和交换空间 0.6707229614257812 GB\n",
      "共享内存的大小，被多个进程共享的内存量 0.01555633544921875 GB\n",
      "可执行程序的代码段大小 0.00262451171875 GB\n",
      "程序的数据段大小 0.13798904418945312 GB\n"
     ]
    }
   ],
   "source": [
    "# %pip install nvidia-ml-py3\n",
    "import pynvml\n",
    "# 初始化 NVML 库\n",
    "pynvml.nvmlInit()\n",
    "\n",
    "# 获取 GPU 数量\n",
    "num_gpus = pynvml.nvmlDeviceGetCount()\n",
    "print(\"GPU 数量：\", num_gpus)\n",
    "\n",
    "# 遍历每个 GPU，获取其资源信息\n",
    "for i in range(num_gpus):\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(i)\n",
    "    gpu_name = pynvml.nvmlDeviceGetName(handle)\n",
    "    gpu_memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU {i}: {gpu_name.decode()}，内存使用情况：{gpu_memory_info.used / 1024 / 1024} MB / {gpu_memory_info.total / 1024 / 1024} MB\")\n",
    "\n",
    "# 关闭 NVML 库\n",
    "pynvml.nvmlShutdown()\n",
    "\n",
    "import psutil\n",
    "# 获取当前进程的内存信息\n",
    "process = psutil.Process()\n",
    "mem_info = process.memory_info()\n",
    "print(\"当前系统内存使用信息\",mem_info)\n",
    "print(\"物理内存中实际驻留的大小\", mem_info.rss/(1024*1024*1024), \"GB\")\n",
    "print(\"虚拟内存的大小，包括实际使用的物理内存和交换空间\", mem_info.vms/(1024*1024*1024), \"GB\")\n",
    "print(\"共享内存的大小，被多个进程共享的内存量\", mem_info.shared/(1024*1024*1024), \"GB\")\n",
    "print(\"可执行程序的代码段大小\", mem_info.text/(1024*1024*1024), \"GB\")\n",
    "print(\"程序的数据段大小\", mem_info.data/(1024*1024*1024), \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xilinx/Documents/llamaindex_ma35_rag/.venv/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "04/26/2024 09:58:37 - [INFO] -sentence_transformers.SentenceTransformer->>>    Load pretrained SentenceTransformer: maidalun1020/bce-embedding-base_v1\n",
      "/home/xilinx/Documents/llamaindex_ma35_rag/.venv/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "04/26/2024 09:58:43 - [INFO] -sentence_transformers.SentenceTransformer->>>    2 prompts are loaded, with the keys: ['query', 'text']\n",
      "04/26/2024 09:58:45 - [INFO] -BCEmbedding.models.RerankerModel->>>    Loading from `maidalun1020/bce-reranker-base_v1`.\n",
      "04/26/2024 09:58:45 - [INFO] -BCEmbedding.models.RerankerModel->>>    Execute device: cuda;\t gpu num: 2;\t use fp16: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %pip install llama-index-llms-ollama\n",
    "# !pip install llama-index\n",
    "# %pip install llama-index-embeddings-ollama\n",
    "# %pip install docx2txt\n",
    "# %pip install llama-index-embeddings-huggingface\n",
    "# %pip install llama-index-embeddings-instructor\n",
    "\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# load the ollama\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from BCEmbedding.tools.llama_index import BCERerank\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "\n",
    "# model set\n",
    "llama2_7b = \"llama2\"\n",
    "llama2_13b = \"llama2:13b\"\n",
    "llama3_8b = \"llama3\"\n",
    "llama3_70b = \"llama3:70b\"\n",
    "\n",
    "\n",
    "# embedding_type = \"llama3\"\n",
    "embedding_type = \"bce\"\n",
    "rebuild = False\n",
    "\n",
    "if embedding_type == \"llama3\":\n",
    "    base_name = \"ma35_rag_base\"\n",
    "    embedding_model = OllamaEmbedding(model_name=llama3_8b,ollama_additional_kwargs={\"mirostat\": 0}) #base_url=\"http://localhost:11434\"\n",
    "elif embedding_type == \"bce\":\n",
    "    base_name = \"ma35_rag_base_bce\"\n",
    "    embed_args = {'model_name': 'maidalun1020/bce-embedding-base_v1', 'max_length': 512, 'embed_batch_size': 256, 'device': 'cuda'}\n",
    "    embedding_model = HuggingFaceEmbedding(**embed_args)\n",
    "else:\n",
    "    print(\"embedding model not correct\\n\")\n",
    "    exit(-1)\n",
    "\n",
    "# connect with the ollama server\n",
    "llm_llama = Ollama(model=llama3_8b, request_timeout=600, temperature=0.1, device='cuda') #base_url = 'http://localhost:11434',\n",
    "# llm_llama2 = Ollama(model=\"llama2:13b\", request_timeout=600, temperature=0.1) #base_url = 'http://localhost:11434',\n",
    "\n",
    "reranker_args = {'model': 'maidalun1020/bce-reranker-base_v1', 'top_n': 5, 'device': 'cuda'}\n",
    "reranker_model = BCERerank(**reranker_args)\n",
    "\n",
    "Settings.llm = llm_llama\n",
    "Settings.embed_model = embedding_model\n",
    "Settings.node_parser = SentenceSplitter(chunk_size=500, chunk_overlap=20)\n",
    "# Settings.num_output = 512\n",
    "# Settings.context_window = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 09:58:46 - [INFO] -chromadb.telemetry.product.posthog->>>    Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "# create a vector storage\n",
    "# %pip install llama-index-vector-stores-chroma\n",
    "import chromadb\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "# initialize client, setting path to save data\n",
    "chroma_client = chromadb.PersistentClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "# define prompt viewing function\n",
    "def display_prompt_dict(prompts_dict):\n",
    "    for k, p in prompts_dict.items():\n",
    "        text_md = f\"**Prompt Key**: {k}<br>\" f\"**Text:** <br>\"\n",
    "        display(Markdown(text_md))\n",
    "        print(p.get_template())\n",
    "        display(Markdown(\"<br><br>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if rebuild :\n",
    "    # %pip install llama-index-readers-web\n",
    "\n",
    "    from llama_index.readers.web import SimpleWebPageReader\n",
    "\n",
    "    documents = SimpleWebPageReader(html_to_text=True).load_data(\n",
    "        [\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/index.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/getting_started_on_prem.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/virtualization.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/ffmpeg/tutorials.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/ffmpeg/quality_analysis.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/ffmpeg/filters.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/gstreamer/tutorials.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/gstreamer/filters.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/gstreamer/xcompositor.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/gstreamer/xabrladder.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/examples/xma/xma_apps.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/specs_and_features.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/package_feed.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/using_ffmpeg.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/using_gstreamer.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/unified_logging.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/tuning_video_quality.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/tuning_pipeline_latency.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/managing_compute_resources.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/c_apis.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/card_management.html\",\n",
    "        \"https://amd.github.io/ama-sdk/v1.1.2/encoder_comp_matrix.html\",\n",
    "        \"https://ffmpeg.org/ffmpeg.html\",\n",
    "        \"https://ffmpeg.org/ffmpeg-resampler.html\",\n",
    "        \"https://ffmpeg.org/ffmpeg-devices.html\",\n",
    "        \"https://ffmpeg.org/ffmpeg-all.html\",\n",
    "        \"https://trac.ffmpeg.org/wiki/Encode/H.264\",\n",
    "        \"https://trac.ffmpeg.org/wiki/Encode/H.265\",\n",
    "        \"https://trac.ffmpeg.org/wiki/Encode/AV1\",\n",
    "        \"https://trac.ffmpeg.org/wiki/Scaling\",\n",
    "        \"https://trac.ffmpeg.org/wiki/Null\",\n",
    "        \"https://trac.ffmpeg.org/wiki/FilteringGuide\",\n",
    "        ]\n",
    "        \n",
    "    )\n",
    "\n",
    "    collection_name = base_name\n",
    "    collection = chroma_client.list_collections()\n",
    "    if collection_name in collection:\n",
    "        chroma_client.delete_collection(collection_name)\n",
    "        chroma_client.clear_system_cache()\n",
    "    chroma_collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "    storage_context = StorageContext.from_defaults(docstore=documents, vector_store=vector_store)\n",
    "\n",
    "    # 这个nodes 有什么用处\n",
    "    from llama_index.core.node_parser import SimpleNodeParser \n",
    "    # Initialize the parser \n",
    "    parser = SimpleNodeParser.from_defaults(chunk_size=500, chunk_overlap=20) \n",
    "    # Parse documents into nodes \n",
    "    nodes = parser.get_nodes_from_documents(documents)\n",
    "    # print(nodes[0])\n",
    "    len(nodes)\n",
    "\n",
    "    # %pip install ipywidgets\n",
    "    # index = VectorStoreIndex.from_documents(documents,storage_context=storage_context,show_progress=True)\n",
    "    index = VectorStoreIndex(nodes,embed_model=embedding_model,storage_context=storage_context,show_progress=True)\n",
    "\n",
    "    # # documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # 读取 HTML 文件\n",
    "# with open(\"local_html/FFMPEG command line arguments - VideoDC - Xilinx Enterprise Wiki.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "#     html_content = file.read()\n",
    "\n",
    "# # 使用 Beautiful Soup 解析 HTML\n",
    "# soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n",
    "# # 提取文档内容\n",
    "# document_text = soup.get_text()\n",
    "\n",
    "# # 打印文档内容\n",
    "# print(document_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index from stored vectors\n",
    "collection_name = base_name\n",
    "collection = chroma_client.list_collections()\n",
    "chroma_collection = chroma_client.get_or_create_collection(name=collection_name)\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store, embed_model=embedding_model,storage_context=storage_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "   \"\"\"explain following ffmpeg command \"ffmpeg -hwaccel ama -f rawvideo -s 1920x1080 -framerate 24 -i cut1_1080p.nv12 -vf 'hwupload' -c:v av1_ama -b:v 5M -f mp4 -y 1.av1_1080p_1.mp4\" \"\"\",\n",
    "\n",
    "   \"\"\"explain following ffmpeg command\n",
    "   ffmpeg -y -hwaccel ama \\\n",
    "      -c:v h264_ama  -out_fmt nv12 -i <INPUT>  \\\n",
    "      -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d]; \\\n",
    "                     [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\" \\\n",
    "      -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv \\\n",
    "      -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv  \\\n",
    "      -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv \\\n",
    "      -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\"\"\",\n",
    "\n",
    "    \n",
    "    \"\"\"Using ffmpeg Decoder a clip that is already encoded in H.264, and will decode the file into a RAW format and save it to disk.\"\"\",\n",
    "    \"\"\"Using ffmpeg encode a RAW 1080p60 clip in YUV420 format. Pass the clip to the MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and saves it to disk. please do not use -re option\"\"\",\n",
    "    \"\"\" Using ffmpeg do the Bit Conversion, To encode YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format' \"\"\",\n",
    "    \"\"\" Using ffmpeg decodes an existing H.264 file and then scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\"\"\",\n",
    "    \"\"\" Using ffmpeg one cmd line, decodes an existing H.264 file and then using scaler_ama scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\"\"\",\n",
    "\n",
    "    \"\"\"How to tuning Latency of MA35D ama codec video transcode,  for example enable ultra low latency for ama_av1 Encoding?\"\"\",\n",
    "    \n",
    "    \"一个ma35D AV1 codec transcode 的处理能力是多少 \",\n",
    "\n",
    "   # the question come from forum\n",
    "    \"\"\"Is max_bitrate implemented in ama sdk ffmpeg, and is it correct that the max bitrate parameter in AMA is irrelevant to VBR?\"\"\",\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = index.as_retriever()\n",
    "# relevant_docs = retriever.retrieve(\"what is the max transcode rate for 1080p30 stream\")\n",
    "# relevant_docs\n",
    "\n",
    "# \"\"\"\n",
    "# response_mode\n",
    "\n",
    "#     REFINE = \"refine\"\n",
    "#     COMPACT = \"compact\"\n",
    "#     SIMPLE_SUMMARIZE = \"simple_summarize\"\n",
    "#     TREE_SUMMARIZE = \"tree_summarize\"\n",
    "#     GENERATION = \"generation\"\n",
    "#     NO_TEXT = \"no_text\"\n",
    "\n",
    "# \"\"\"\n",
    "\n",
    "# ResponseMode为tree_summarize时，LLM会对每一段文本进行最大长度的分割，并进行连续的读取和询问。这种模式的优点是可以保证对文本的完整理解和回答，但如果没有正确处理分割段落的情况，可能会导致错误的生成结果\n",
    "# ResponseMode为generation时，生成的回答不依赖于文档的内容，只基于提供的问题进行生成。这种模式适用于纯粹的问题回\n",
    "# ResponseMode为no_text时，生成的回答中不包含任何内容，仅作为占位符使用\n",
    "# ResponseMode为simple_summarize时，LLM会截取每段文本的相关句子（通常是第一句），并进行提炼生成回答。这种模式适用于对结果要求不高的场景。\n",
    "# ResponseMode为refine时，如果只有一个文本块（text_chunk），则会正常生成回答。但如果存在多个文本块，则会以类似轮询的方式迭代生成回答。这种模式可以对多个文本块进行迭代式的回答生成，逐步完善回答内容。\n",
    "# ResponseMode为compact时，生成的回答会将多个文本块（text_chunk）压缩到设定的最大长度，并生成一次回答。然后，根据后续内容对以往的答案进行改进和完善（即进行多次迭代）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are hellpful, respectful and honest video transcode assistant and very faimilay with ffmpge, and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/transcode.\n",
      "Context information from multiple sources is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the information from multiple sources and not prior knowledge\n",
      "please read the above context information carefully. and anwer the question.\n",
      "if the question is not releate with video process, just say it is not releated with my knowledge base.\n",
      "if you don't know the answer, just say that I don't know.\n",
      "Answers need to be precise and concise.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "query_engine = index.as_query_engine(response_mode='simple_summarize', similary_threshold=0.1, similarity_top_k=5)\n",
    "\n",
    "template = (\n",
    "    \"You are hellpful, respectful and honest video transcode assistant and very faimilay with ffmpge, and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/transcode.\\n\"\n",
    "    \"Context information from multiple sources is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the information from multiple sources and not prior knowledge\\n\"\n",
    "    \"please read the above context information carefully. and anwer the question.\\n\"\n",
    "    \"if the question is not releate with video process, just say it is not releated with my knowledge base.\\n\"\n",
    "    \"if you don't know the answer, just say that I don't know.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_template}\n",
    ")\n",
    "\n",
    "prompts_dict = query_engine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52055836c5bf4d38a2a7b3526782dbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 09:58:58 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1: explain following ffmpeg command \"ffmpeg -hwaccel ama -f rawvideo -s 1920x1080 -framerate 24 -i cut1_1080p.nv12 -vf 'hwupload' -c:v av1_ama -b:v 5M -f mp4 -y 1.av1_1080p_1.mp4\" \n",
      "Answer:This FFmpeg command is used to encode a raw video file into an MP4 container using the AV1 codec with hardware acceleration.\n",
      "\n",
      "Here's a breakdown of the command:\n",
      "\n",
      "* `-hwaccel ama`: This option enables the AMD MultiMedia Accelerator (AMA) hardware accelerator for FFmpeg.\n",
      "* `-f rawvideo -s 19:20x10:80`: The input file format is set to `rawvideo`, and the resolution is specified as `1920x1080`.\n",
      "* `-framerate 24`: The frame rate of the input video is set to 24 frames per second.\n",
      "* `-i cut1_10:80p.nv12`: The input file name is `cut1_10:80p.nv12`, which is a raw video file in NV12 format.\n",
      "* `-vf 'hwupload'`: This option applies the `hwupload` filter to the input video, which uploads the video data to the AMA hardware accelerator for processing.\n",
      "* `-c:v av1_ama -b:v 5M`: The video codec is set to AV1 with AMA acceleration, and the target bitrate is set to 5 megabits per second (Mbps).\n",
      "* `-f mp4 -y 1.av1_10:80p_1.mp4`: The output file format is set to MP4, and the output file name is `1.av1_10:80p_1.mp4`.\n",
      "\n",
      "In summary, this command encodes a raw video file in NV12 format with a resolution of 1920x1080 at 24 frames per second into an MP4 container using the AV1 codec with AMA hardware acceleration.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6132f56b3f43c78650dadc3a2d9005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 09:59:08 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question2: explain following ffmpeg command\n",
      "   ffmpeg -y -hwaccel ama       -c:v h264_ama  -out_fmt nv12 -i <INPUT>        -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d];                      [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\"       -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv       -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv        -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv       -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "Answer:This FFmpeg command is used to scale a video input to four different resolutions (1920x1080, 1280x720, 720x480, and 360x240) using the AMA (AMD MultiMedia Accelerator) hardware-accelerated scaler. The output of each resolution will be saved as a separate RAW YUV file.\n",
      "\n",
      "Here's a breakdown of the command:\n",
      "\n",
      "* `-y` - Overwrite existing files without asking.\n",
      "* `-hwaccel ama` - Use the AMA hardware-accelerated scaler.\n",
      "* `-c:v h264_ama` - Set the video codec to H.264 (hardware-accelerated).\n",
      "* `-out_fmt nv12` - Set the output format to NV12.\n",
      "* `-i <INPUT>` - Input the video file.\n",
      "* `filter_complex` - Apply a complex filter chain.\n",
      "\t+ `scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d];` - Scale the input video to four different resolutions using the AMA scaler. The output of each resolution will be stored in variables `a`, `b`, `c`, and `d`.\n",
      "\t+ `[a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1];` - Download the scaled video frames and convert them to NV12 format. The output of each resolution will be stored in variables `a1`, `b1`, `c1`, and `d1`.\n",
      "* `-map '[a1]'` - Map the output of variable `a1` to a file.\n",
      "\t+ `-f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv` - Save the scaled video frames as a RAW YUV file named `scale_1080p.yuv`.\n",
      "* Repeat the same process for variables `b1`, `c1`, and `d1` to save the scaled video frames at resolutions 1280x720, 720x480, and 360x240.\n",
      "\n",
      "In summary, this command is used to scale a video input to four different resolutions using the AMA hardware-accelerated scaler and save each resolution as a separate RAW YUV file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ab4665e1f34f95b4f1940c70a9e0ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 09:59:12 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question3: Using ffmpeg Decoder a clip that is already encoded in H.264, and will decode the file into a RAW format and save it to disk.\n",
      "Answer:The command line for decoding a H.264 clip using FFmpeg's AMA (AMD Multimedia Accelerator) decoder is:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> -vf hwdownload,format=nv12 -f rawvideo /tmp/dec_out.nv12\n",
      "```\n",
      "\n",
      "This command will decode the input file into a RAW format and save it to disk.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f953450eae49c18119c40c8c1dcd92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 09:59:15 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question4: Using ffmpeg encode a RAW 1080p60 clip in YUV420 format. Pass the clip to the MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and saves it to disk. please do not use -re option\n",
      "Answer:Here is the command:\n",
      "\n",
      "```\n",
      "ffmpeg -hwaccel ama -i <INPUT> -vf \"format=yuv420p, hwupload\" -c:v av1_ama -b:v 5M -f mp4 -y output.mp4\n",
      "```\n",
      "\n",
      "Note that I did not use the `-re` option as per your request.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77cb007406904b9e9c6277e79eeeaecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 09:59:19 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question5:  Using ffmpeg do the Bit Conversion, To encode YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format' \n",
      "Answer:To convert YUV 4:2:2 10-bit pixel format to YUV 4:2:0 8-bit format using FFmpeg, you can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -hwaccel ama -i <INPUT> -vf \"format=yuv420p, hwupload\" -c:v h264_ama -b:v 1M -out_fmt yuv420p -f mp4 <OUTPUT>\n",
      "```\n",
      "\n",
      "This command uses the `format` filter to convert the input YUV 4:2:2 10-bit pixel format to YUV 4:2:0 8-bit format, and then encodes it using the H.264 AMA encoder.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd00a44fe77f4d92976adf694a26ebae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 09:59:26 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question6:  Using ffmpeg decodes an existing H.264 file and then scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:Based on the provided context information, I can help you with that.\n",
      "\n",
      "To answer your question:\n",
      "\n",
      "Using ffmpeg decodes an existing H.264 file and then scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under `/tmp/scale_<resolution>.yuv`, you can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d]; [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\" -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "```\n",
      "\n",
      "This command uses the `scaler_ama` filter to scale the input video into four different resolutions (1920x1080, 1280x720, 720x480, and 360x240) and saves the RAW outputs to disk under `/tmp/scale_<resolution>.yuv`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "092d9d0de1ed4e3e8b9b9be4dbeff441",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 09:59:34 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question7:  Using ffmpeg one cmd line, decodes an existing H.264 file and then using scaler_ama scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:Based on the provided context information, here is a possible command line that achieves the desired result:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i input.mp4 -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d]; [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\" -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "```\n",
      "\n",
      "This command line uses the `scaler_ama` filter to scale the input H.264 file into four different resolutions (1920x1080, 1280x720, 720x480, and 360x240) and saves the RAW outputs to disk under `/tmp/scale_<resolution>.yuv`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7fa01ca0f64cb9aff799d7317567ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 09:59:41 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question8: How to tuning Latency of MA35D ama codec video transcode,  for example enable ultra low latency for ama_av1 Encoding?\n",
      "Answer:According to the provided context information, to tune the latency of MA35D AMA codec video transcode, you can use the following command:\n",
      "\n",
      "`ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> -filter_complex \"scaler_ama=outputs=1:out_res=(1920x1080)\" -c:v av1_ama -frames 50 -lookahead_depth 0 -latency_logging enable -f rawvideo -b:v 6M /tmp/hevc_to_scale_to_h264.h264`\n",
      "\n",
      "To enable ultra low latency for AMA_AV1 encoding, you can add the following options:\n",
      "\n",
      "* `-tune_metrics` with value `vmaf`\n",
      "* `-latency-ms` with a specific value (e.g., `12`)\n",
      "* `-no-bll` with value `0`\n",
      "\n",
      "Here's an example command:\n",
      "\n",
      "`ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> -filter_complex \"scaler_ama=outputs=1:out_res=(1920x1080)\" -c:v av1_ama -frames 50 -lookahead_depth 0 -tune_metrics vmaf -latency-ms 12 -no-bll 0 -f rawvideo -b:v 6M /tmp/hevc_to_scale_to_h264.h264`\n",
      "\n",
      "Please note that the specific values for `-tune_metrics`, `-latency-ms`, and `-no-bll` may vary depending on your specific use case and requirements.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35de6526c414475a70fb99251660303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 09:59:44 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question9: 一个ma35D AV1 codec transcode 的处理能力是多少 \n",
      "Answer:Based on the provided context information, it is mentioned that:\n",
      "\n",
      "* The MA35D card nominally produces video quality (VQ) that is closely correlated to x264 medium, x265 medium and x265 slow presets.\n",
      "* The video processing power of the MA35D cards can be harnessed in many different ways, from running a few high-definition jobs to running many low-resolution ones, with or without scaling.\n",
      "\n",
      "However, there is no specific information provided about the transcoding capabilities of the MA35D AV1 codec. Therefore, I don't know the answer to this question.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff1bfbd6a3c499abc37fa19fa6fb8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 09:59:50 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question10: Is max_bitrate implemented in ama sdk ffmpeg, and is it correct that the max bitrate parameter in AMA is irrelevant to VBR?\n",
      "Answer:According to the context information provided, `max_bitrate` is an option for the AMD AMA Video SDK encoder, with valid values ranging from 0 to 3.5e+10.\n",
      "\n",
      "Regarding your question, it seems that `max_bitrate` is indeed implemented in AMA SDK FFmpeg, as it is mentioned alongside other bitrate-related options such as `-b:v`.\n",
      "\n",
      "As for whether the `max_bitrate` parameter is irrelevant to VBR (Variable Bit Rate), the answer appears to be \"no\". The context information suggests that when `max_bitrate` is specified and is higher than the average bitrate, the encoder will use a variable bitrate mode (`VBR`). This implies that `max_bitrate` does have an impact on VBR encoding.\n",
      "\n",
      "Therefore, my answer is: Yes, `max_bitrate` is implemented in AMA SDK FFmpeg, and it is not correct to say that the `max bitrate` parameter in AMA is irrelevant to VBR.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Here no database input, so no answer\n",
    "counter = 0\n",
    "for question in questions:\n",
    "   counter = counter + 1\n",
    "   query_response = query_engine.query(question)\n",
    "   print(f\"Question{counter}: {question}\")\n",
    "   print(f\"Answer:{query_response.response}\")\n",
    "   \n",
    "\n",
    "   # print(\" \")\n",
    "   # print(f\"source_nodes length:{len(query_response.source_nodes)}\")\n",
    "   # for i, result in enumerate(query_response.source_nodes, start=1):\n",
    "   #    print(result)\n",
    "\n",
    "   #    # print(f\"Result {i}: Document ID {result['id']}, Title '{result['title']}', Similarity: {result.score}\")\n",
    "   #    print(f\"Result {i}\\n Similarity: {result.score}\\n content '{result.get_content()}\")\n",
    "\n",
    "   # print()\n",
    "   # # print(response.get_formatted_sources(length=10))\n",
    "   # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are video transcode expert and very faimilay with ffmpge and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/transcode.\n",
      "Context information from multiple sources is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the information from multiple sources and not prior knowledge\n",
      "please read the above context information carefully. and anwer the question.\n",
      "if the question is not releate with video process, just say it is not releated with my knowledge base.\n",
      "if you don't know the answer, just say that I don't know.\n",
      "Answers need to be precise and concise.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}.\n",
      "We have provided an existing answer: {existing_answer}.\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "-------------\n",
      "{context_msg}\n",
      "-------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "if the question is 'who are you' , just say I am a video expert.\n",
      "Answers need to be precise and concise.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "query_engine_rerank = index.as_query_engine(response_mode='refine',similarity_top_k=50, temperature=0.6,node_postprocessors=[reranker_model])\n",
    "\n",
    "template = (\n",
    "    \"You are hellpful, respectful and honest video transcode assistant and very faimilay with ffmpge, and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/transcode.\\n\"\n",
    "    \"Context information from multiple sources is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the information from multiple sources and not prior knowledge\\n\"\n",
    "    \"please read the above context information carefully. and anwer the question.\\n\"\n",
    "    \"if the question is not releate with video process, just say it is not releated with my knowledge base.\\n\"\n",
    "    \"if you don't know the answer, just say that I don't know.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "\n",
    "query_engine_rerank.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_template}\n",
    ")\n",
    "\n",
    "\n",
    "template = (\n",
    "    \"The original query is as follows: {query_str}.\\n\"\n",
    "    \"We have provided an existing answer: {existing_answer}.\\n\"\n",
    "    \"We have the opportunity to refine the existing answer (only if needed) with some more context below.\\n\"\n",
    "    \"-------------\\n\"\n",
    "    \"{context_msg}\\n\"\n",
    "    \"-------------\\n\"\n",
    "    \"Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\n\"\n",
    "    \"if the question is 'who are you' , just say I am a video expert.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"Refined Answer: \"\n",
    ")\n",
    "\n",
    "\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "query_engine_rerank.update_prompts(\n",
    "    {\"response_synthesizer:refine_template\": qa_template}\n",
    ")\n",
    "\n",
    "prompts_dict = query_engine_rerank.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "449364be6ea849f48fc89e0aaf719126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (519 > 512). Running this sequence through the model will result in indexing errors\n",
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "04/26/2024 09:59:54 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 09:59:58 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:00:01 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:00:04 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:00:08 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1: explain following ffmpeg command \"ffmpeg -hwaccel ama -f rawvideo -s 1920x1080 -framerate 24 -i cut1_1080p.nv12 -vf 'hwupload' -c:v av1_ama -b:v 5M -f mp4 -y 1.av1_1080p_1.mp4\" \n",
      "Answer:I'm a video expert!\n",
      "\n",
      "The given FFmpeg command is used for transcoding a RAW video clip with the following settings:\n",
      "\n",
      "* Input file: `cut1_10_80p.nv12`\n",
      "* Resolution: 1920x1080 (19.2x10.8) in four different resolutions: 1920x1080, 1280x720, 720x480, and 360x240\n",
      "* Frame rate: 24\n",
      "* Color space: NV12 (YUV 4:2:0, 10-bit)\n",
      "* Hardware acceleration: AMA (AMD MultiMedia Accelerator) for uploading and converting the input video to a format that can be processed by the AMA accelerator.\n",
      "* Output file: `av1_ama.mp4`\n",
      "\n",
      "The command does not encode the video but rather saves the RAW outputs to disk.\n",
      "\n",
      "Note: The context provided about CRF mode, qp option, and basic transcoding is not directly related to this specific FFmpeg command.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d0f79f023f45609d6761dbfb09f288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:00:14 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:00:18 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:00:21 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:00:24 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:00:28 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question2: explain following ffmpeg command\n",
      "   ffmpeg -y -hwaccel ama       -c:v h264_ama  -out_fmt nv12 -i <INPUT>        -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d];                      [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\"       -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv       -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv        -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv       -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "Answer:I'm a video expert!\n",
      "\n",
      "The FFmpeg command is used to scale a video input to multiple resolutions and frame rates, and then save each scaled stream as a separate YUV file.\n",
      "\n",
      "The command uses the `-filter_complex` flag to combine multiple filters together, including the `scaler_ama` filter, which creates four output resolutions from the input stream. The `hwdownload` filter is used to download each of the four scaled streams and format them as NV12.\n",
      "\n",
      "The command then maps each of the four scaled streams to a separate YUV file using the `-map` options. The files are saved under `/tmp/_scale<resolution>.yuv`, where `<resolution>` is the resolution of the corresponding stream (e.g., `10_80p`, `720p`, etc.).\n",
      "\n",
      "Additionally, this command uses AMD AMA Video SDK for hardware acceleration and H.264 encoding.\n",
      "\n",
      "The new context provides more information on the use of 2D GPU utilities, including video processing accelerators and machine learning-based face ROI models. However, these features are not directly related to the original query, so I will stick with the original answer.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c739635ca65b464296fe8d04f3008870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:00:31 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:00:37 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:00:43 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:00:49 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:00:59 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question3: Using ffmpeg Decoder a clip that is already encoded in H.264, and will decode the file into a RAW format and save it to disk.\n",
      "Answer:I am a video expert.\n",
      "\n",
      "To decode a clip that is already encoded in H.264 and save it to disk as a RAW format, you can use the following FFmpeg command:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> -vf hwdownload,format=nv12 -f rawvideo /tmp/dec_out.nv12\n",
      "```\n",
      "\n",
      "However, if you want to scale the output to different resolutions and save each resolution as a separate RAW file, you can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full)(1280x720|half)(720x480|half)(360x240|half) [a][b][c][d]; [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\" -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "```\n",
      "\n",
      "This command uses the `scaler_ama` filter to create 4 output resolutions from the input stream, and then saves each resolution as a separate RAW file.\n",
      "\n",
      "If you want to decode the H.264 clip into multiple resolutions with different CRF (Constant Rate Factor) values, you can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -re -hwaccel ama -f rawvideo -s 1920x1080 -framerate 60 -i <INPUT> -vf \"hwupload\" -c:v av1_ama -crf 1 -qp 0 -f mp4 sn1_crf_hq.mp4\n",
      "```\n",
      "\n",
      "This command decodes the H.264 clip into a RAW format and then encodes it as an AV1 stream with CRF quality set to 1 (highest) and QP (Quality Parameter) set to 0.\n",
      "\n",
      "If you want to decode the H.264 clip into multiple resolutions with different CRF values, you can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -re -hwaccel ama -f rawvideo -s 1920x1080 -framerate 60 -i <INPUT> -vf \"hwupload\" -c:v av1_ama -crf 1 -qp 255 -f mp4 sn1_crf_lq.mp4\n",
      "```\n",
      "\n",
      "This command decodes the H.264 clip into a RAW format and then encodes it as an AV1 stream with CRF quality set to 1 (highest) and QP set to 255 (lowest).\n",
      "\n",
      "If you want to transcode the H.264 clip to HEVC at a bitrate of 8Mbps, you can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -i <INPUT> -c:v hevc_ama -b:v 8M -f rawvideo /tmp/h264_to_hevc.hevc\n",
      "```\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49068820d5649fb8ac5adcc03976009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:01:06 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:01:08 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:01:10 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:01:12 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:01:14 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question4: Using ffmpeg encode a RAW 1080p60 clip in YUV420 format. Pass the clip to the MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and saves it to disk. please do not use -re option\n",
      "Answer:I am a video expert.\n",
      "\n",
      "The refined answer remains:\n",
      "\n",
      "`ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt yuv420p -i <INPUT> -vf hwdownload,format=yuv420p -f rawvideo -c:v ma35d -b:v 5k -pix_fmt yuv420p -crf 18 output.mp4`\n",
      "\n",
      "The additional context provides more information on encoding options and formats, but it does not change the original query's requirements.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c007eb39b84d3c9c77bdef4922a33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:01:16 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:01:19 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:01:23 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:01:26 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:01:30 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question5:  Using ffmpeg do the Bit Conversion, To encode YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format' \n",
      "Answer:I am a video expert.\n",
      "\n",
      "To refine the original answer:\n",
      "\n",
      "The command `ffmpeg -i input.yuv -c:v rawvideo -pix_fmt yuv422p10le -f rawvideo output.yuv -c:v rawvideo -pix_fmt yuv420p8le` can be used to encode YUV 4:2:2 10-bit pixel format to YUV 4:2:0 8-bit format using FFmpeg.\n",
      "\n",
      "However, considering the new context about AMD AMA Video SDK and chroma subsampling operations, it's important to note that the original command assumes a raw YUV file as input. If your input file is not in this format, you may need to use additional filters or conversions to get the desired output.\n",
      "\n",
      "Additionally, if you're working with the AMD AMA Video SDK, ensure that your environment is properly configured by sourcing the setup script `/opt/amd/ama/ma35/scripts/setup.sh` as described in the Environment Setup section.\n",
      "\n",
      "If you want to optimize encoding time, consider using `fast`, `faster`, or `ultrafast` options. However, keep in mind that these options may compromise quality.\n",
      "\n",
      "To ensure compatibility with dumb players, use `-vf format=yuv420p` (or the alias `-pix_fmt yuv420p`) for your output to work in QuickTime and most other players.\n",
      "\n",
      "Remember that if your input files are RGB, you'll need to convert them to YUV color space using `ffmpeg -c:v libx264rgb`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57fba59019ac493b9c429516096a1c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:01:35 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:01:39 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:01:44 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:01:49 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:01:53 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question6:  Using ffmpeg decodes an existing H.264 file and then scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:I am a video expert.\n",
      "\n",
      "Using ffmpeg, you can decode an existing H.264 file and scale it into 4 different resolutions (1080p, 720p, 480p, and 240p) using the `scaler_ama` filter with the `-filter_complex` option.\n",
      "\n",
      "Here's a breakdown of the command:\n",
      "\n",
      "* The input file is decoded and scaled into 4 different resolutions using the `scaler_ama` filter.\n",
      "* Each output resolution is saved as a separate YUV file under `/tmp/_scale<resolution>.yuv`.\n",
      "* The `-map` option is used to specify which outputs (in this case, `[a1]`, `[b1]`, `[c1]`, and `[d1]`) should be written to disk.\n",
      "\n",
      "Additionally, the command line also demonstrates how to transcode the scaled outputs into different formats such as HEVC, AV1, and H.264, with varying bitrates and save them to disk under `/tmp/<encoder format>_<resolution>.mp4`.\n",
      "\n",
      "So, the answer is: Yes, using ffmpeg, you can decode an existing H.264 file and scale it into 4 different resolutions (1080p, 720p, 480p, and 240p) and save the RAW outputs to disk under `/tmp/_scale<resolution>.yuv`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c12fcc7ca7b8401fa0406e5902250674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:01:58 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:04 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:09 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:14 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:19 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question7:  Using ffmpeg one cmd line, decodes an existing H.264 file and then using scaler_ama scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:I'm glad to refine my previous answer!\n",
      "\n",
      "To answer your query:\n",
      "\n",
      "You can use the following command line to achieve this:\n",
      "```\n",
      "ffmpeg -i <INPUT> -hwaccel ama -c:v h264_ama -out_fmt nv12 -filter_complex \"scaler_ama=outputs=4:out_res=(1080x1080|full|nv12)(1080x720|half|nv12)(720x480|half|nv12)(360x240|half|nv12) [a][b][c][d]; [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\" -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "```\n",
      "This command line decodes the input H.264 file, scales it into 4 resolutions (1080p, 720p, 480p, and 240p) using the `scaler_ama` filter, and saves the RAW outputs to disk under `/tmp/scale_<resolution>.yuv`.\n",
      "\n",
      "I hope this refined answer meets your requirements!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57db32314deb43a5b99f8da90e3cae73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:02:21 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:24 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:27 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:29 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:32 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question8: How to tuning Latency of MA35D ama codec video transcode,  for example enable ultra low latency for ama_av1 Encoding?\n",
      "Answer:To tune latency of MA35D AMA codec video transcode for example enable ultra low latency for AMA_AV1 encoding, you can use the following FFmpeg command:\n",
      "\n",
      "```ffmpeg -y -hwaccel ama -hwaccel_device /dev/ama_transcoder0 -s 19xx -framerate 60 -pix_fmt yuv420p -i <INPUT> -vf hwupload -c:v av1_ama -tune_metrics 4 -b:v 2M -lookahead_depth 0 -f rawvideo <OUTPUT>\n",
      "```\n",
      "\n",
      "In this command, the `lookahead_depth` option is set to 0, which enables ultra-low latency for AMA_AV1 encoding. Additionally, you can adjust the values of `-w`, `-h`, and `-pix_fmt` according to your specific use case.\n",
      "\n",
      "Note: The original answer remains unchanged as it provides a precise and concise solution to the query.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e166f2e8f723425cb0ab8eee6157ebd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:02:34 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:37 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:39 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:40 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:41 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question9: 一个ma35D AV1 codec transcode 的处理能力是多少 \n",
      "Answer:I am a video expert.\n",
      "\n",
      "Refined Answer:\n",
      "The MA35D AV1 codec transcode processing ability is approximately 8x for 4Kp60, as observed in the load report where quarter of encoder resources are consumed.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae339f904dd64a869f0d42863cf32221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:02:45 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:48 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:52 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:55 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:02:59 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question10: Is max_bitrate implemented in ama sdk ffmpeg, and is it correct that the max bitrate parameter in AMA is irrelevant to VBR?\n",
      "Answer:Based on the additional context about AMA SDK FFmpeg, SVT-AV1 options, and libvpx, I refine my previous answer as follows:\n",
      "\n",
      "* The `max_bitrate` option is not implemented in AMA SDK FFmpeg.\n",
      "* The `max bitrate` parameter in AMA (SVT-AV1) is irrelevant to VBR (Variable Bitrate), as it would imply a fixed maximum bitrate. In VBR mode, the bitrate is adjusted dynamically based on the complexity of the content.\n",
      "\n",
      "The new context about libvpx and SVT-AV1 options provides more insight:\n",
      "\n",
      "* The `max_bitrate` option is not applicable to VBR encoding in libvpx.\n",
      "* The `b` (target-bitrate) option in libvpx allows you to set a maximum bitrate for the video stream, which is different from the AMA SDK FFmpeg where the `max bitrate` parameter has no relevance to VBR mode.\n",
      "\n",
      "In summary, the original answer remains unchanged, and the additional context reinforces the idea that `max_bitrate` has no relevance in VBR mode.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# questions = [\n",
    "# ]\n",
    "\n",
    "counter = 0\n",
    "for question in questions:\n",
    "   counter = counter + 1\n",
    "   query_response = query_engine_rerank.query(question)\n",
    "   print(f\"Question{counter}: {question}\")\n",
    "   print(f\"Answer:{query_response.response}\")\n",
    "\n",
    "   print(\"\")\n",
    "   # print(f\"source_nodes length:{len(query_response.source_nodes)}\")\n",
    "   # for i, result in enumerate(query_response.source_nodes, start=1):\n",
    "   #    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:summary_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a Video ffmpeg & gstreamer technolodge expert and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/scale/transcode.\n",
      "Context information from multiple sources is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the information from multiple sources and not prior knowledge, please read the sources carefully.\n",
      "if the question is not releate with the RDMA, just say it is not releated with my knowledge base.\n",
      "if you don't know the answer, just say that I don't know.\n",
      "if the question is 'who are you' , just say I am a FPGA and RDMA expert.\n",
      "Answers need to be precise and concise.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "# response_mode 有几种模式可选，refine， compact, tree_summarize 等，每一种都有对应的promopt template\n",
    "query_engine_tree_summarize = index.as_query_engine(response_mode='tree_summarize',similary_threshold=0.1, similarity_top_k=30, node_postprocessors=[reranker_model])\n",
    "\n",
    "template = (\n",
    "    \"You are a Video ffmpeg & gstreamer technolodge expert and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/scale/transcode.\\n\"\n",
    "    \"Context information from multiple sources is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the information from multiple sources and not prior knowledge, please read the sources carefully.\\n\"\n",
    "    \"if the question is not releate with the RDMA, just say it is not releated with my knowledge base.\\n\"\n",
    "    \"if you don't know the answer, just say that I don't know.\\n\"\n",
    "    \"if the question is 'who are you' , just say I am a FPGA and RDMA expert.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "query_engine_tree_summarize.update_prompts(\n",
    "    {\"response_synthesizer:summary_template\": qa_template}\n",
    ")\n",
    "\n",
    "prompts_dict = query_engine_tree_summarize.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f782340f431b4e7a8714495742826962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:03:07 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1: explain following ffmpeg command \"ffmpeg -hwaccel ama -f rawvideo -s 1920x1080 -framerate 24 -i cut1_1080p.nv12 -vf 'hwupload' -c:v av1_ama -b:v 5M -f mp4 -y 1.av1_1080p_1.mp4\" \n",
      "Answer:This FFmpeg command is used to encode a raw video file in NV12 format, with a resolution of 1920x1080 and a frame rate of 24 frames per second, into an MP4 container using the AV1 codec.\n",
      "\n",
      "Here's a breakdown of the command:\n",
      "\n",
      "* `-hwaccel ama`: This flag tells FFmpeg to use the AMD AMA (Multimedia Accelerator) hardware acceleration module.\n",
      "* `-f rawvideo`: This flag specifies that the input file is in raw video format.\n",
      "* `-s 19:20x10:80`: This flag sets the resolution of the input file to 1920x1080.\n",
      "* `-framerate 24`: This flag sets the frame rate of the input file to 24 frames per second.\n",
      "* `-i cut1_10:80p.nv12`: This flag specifies the input file, which is a raw video file in NV12 format with a resolution of 1920x1080 and a frame rate of 24 frames per second.\n",
      "* `-vf 'hwupload'`: This flag applies the `hwupload` filter to the input file. The `hwupload` filter uploads the input data to the AMA device for processing.\n",
      "* `-c:v av1_ama`: This flag sets the video codec to AV1, which is a hardware-accelerated codec provided by AMD.\n",
      "* `-b:v 5M`: This flag sets the target bitrate of the encoded stream to 5 megabits per second.\n",
      "* `-f mp4`: This flag specifies that the output file should be in MP4 format.\n",
      "* `-y 1.av1_10:80p_1.mp4`: This flag specifies the output file name, which is `1.av1_1080p_1.mp4`.\n",
      "\n",
      "Overall, this command is used to encode a raw video file into an MP4 container using the AV1 codec and AMD AMA hardware acceleration.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262cd485056b46469b8977e147443322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:03:15 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question2: explain following ffmpeg command\n",
      "   ffmpeg -y -hwaccel ama       -c:v h264_ama  -out_fmt nv12 -i <INPUT>        -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d];                      [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\"       -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv       -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv        -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv       -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "Answer:This FFmpeg command is used to scale a video input to multiple resolutions and save the output as RAW YUV files.\n",
      "\n",
      "Here's a breakdown of the command:\n",
      "\n",
      "* `-y` tells FFmpeg to overwrite any existing files without prompting.\n",
      "* `-hwaccel ama` enables hardware acceleration using AMD's AMA (Multimedia Accelerator) technology.\n",
      "* `-c:v h264_ama` specifies the video codec as H.264, which is accelerated by the AMA device.\n",
      "* `-out_fmt nv12` sets the output format to NV12, a YUV 4:2:0 format.\n",
      "\n",
      "The `filter_complex` option is used to create a filter graph that performs the following operations:\n",
      "\n",
      "1. `scaler_ama=outputs=4:out_res=(19...|full|nv12)`:\n",
      "\t* This creates four output streams with different resolutions (1920x1080, 1280x720, 720x480, and 360x240).\n",
      "\t* Each stream is in the full resolution and NV12 format.\n",
      "2. `[a][b][c][d]`: These are the output labels for each of the four streams.\n",
      "\n",
      "The `hwdownload` filter is used to convert the AMA device's internal buffer format to NV12, which is then saved as a RAW YUV file using the `-f rawvideo` and `-pix_fmt nv12` options. The output files are saved with the names `/tmp/scale_<resolution>.yuv`, where `<resolution>` is the scaled resolution (e.g., 1920x1080).\n",
      "\n",
      "In summary, this command takes an input video, scales it to four different resolutions using AMD's AMA device, and saves each scaled stream as a RAW YUV file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e15a3dfea14c4afda00559d1e5871b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:03:23 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question3: Using ffmpeg Decoder a clip that is already encoded in H.264, and will decode the file into a RAW format and save it to disk.\n",
      "Answer:You can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -out_fmt nv12 -i <INPUT> \\\n",
      "      -vf hwdownload,format=nv12 -f rawvideo /tmp/dec_out.nv12\n",
      "```\n",
      "\n",
      "Explanation of the flags:\n",
      "\n",
      "* `ffmpeg`: The ffmpeg application, which is provided by AMD, and moved to the top of the PATH when you sourced the setup.sh script.\n",
      "* `-hwaccel ama`: Instructs FFmpeg to use accelerated plugins provided by AMD AMA Video SDK.\n",
      "* `-c:v h264_ama`: Declares the decoder's codec for video (as opposed to audio `-c: a ...`) is the hardware-accelerated H.264 decoder.\n",
      "* `-out_fmt nv12`: Specifies nv12 output format for the decoded video. Note that this option has to be specified twice: 1) To convert from the internal buffer format to `nv12` in the decoder and 2) To convert when transferring to the host.\n",
      "* `-f rawvideo`: This signifies that the video is in a raw format, without container or other metadata/information about the clip.\n",
      "* `-i <INPUT>`: The input file to be transcoded.\n",
      "* `-vf hwdownload`: Internally, the decoder operates on AMD AMA Video SDK type buffers to improve performance. To convert back to a host-buffer, you must execute this filter.\n",
      "* `-y`: Enable overwrite without prompting the user if they're sure.\n",
      "* `/tmp/dec_out.nv12`: The decoder will save the file to the path above.\n",
      "\n",
      "This command decodes an H.264 encoded clip into a RAW format and saves it to disk.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f9c999e204a41fdb11b227ab7021a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:03:27 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question4: Using ffmpeg encode a RAW 1080p60 clip in YUV420 format. Pass the clip to the MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and saves it to disk. please do not use -re option\n",
      "Answer:Based on the provided information, here is the command line that uses ffmpeg to encode a RAW 10.80p60 clip in YUV420 format using MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and saves it to disk:\n",
      "\n",
      "```\n",
      "ffmpeg -hwaccel ama -i <INPUT> -vf \"format=yuv420p, hwupload\" -c:v av1_ama -b:v 5M -f mp4 -y output.mp4\n",
      "```\n",
      "\n",
      "Note that I did not use the `-re` option as per your request.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcbc1588ab343f782d2b4327f41e334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:03:33 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question5:  Using ffmpeg do the Bit Conversion, To encode YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format' \n",
      "Answer:To encode YUV 4:2:2 10-bit pixel format to YUV 4:2:0 8-bit format using FFmpeg, you can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -hwaccel ama -i <INPUT> -vf \"format=yuv420p, hwupload\" -c:v h264_ama -b:v 1M <OUTPUT>\n",
      "```\n",
      "\n",
      "Explanation of the flags:\n",
      "\n",
      "* `-re` is not used in this case as we are converting pixel format.\n",
      "* `hwaccel ama` enables the AMA (AMD Multimidia Accelerator) hardware acceleration for the H.264 encoder.\n",
      "* `-i <INPUT>` specifies the input file.\n",
      "* `-vf \"format=yuv420p, hwupload\"` converts the input YUV 4:2:2 10-bit pixel format to YUV 4:2:0 8-bit format using the `hwupload` filter.\n",
      "* `-c:v h264_ama` sets the video codec to H.264 with AMA acceleration.\n",
      "* `-b:v 1M` sets the target bitrate for the encoded stream.\n",
      "\n",
      "Note that this command assumes you have an input file in YUV 4:2:2 10-bit pixel format and you want to encode it to YUV 4:2:0 8-bit format.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9c9b3ffad454ecfa4398928d24bb47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:03:40 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question6:  Using ffmpeg decodes an existing H.264 file and then scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:Based on the provided information, I can help you with that.\n",
      "\n",
      "The command line for decoding an existing H.264 file and scaling it into multiple resolutions is:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama \\\n",
      "-c:v h264_ama -i <INPUT> \\\n",
      "-filter_complex \"scaler_ama=outputs=4:out_res=(19,20x10,80|full)(12,80x720|full)(720x480|full)(360x240|full) [a][b][c][d]\" \\\n",
      "-map '[a]' -f rawvideo -pix_fmt nv12 -y /tmp/_scale1080p.yuv \\\n",
      "-map '[b]' -f rawvideo -pix_fmt nv12 -y /tmp/_scale720p.yuv \\\n",
      "-map '[c]' -f rawvideo -pix_fmt nv12 -y /tmp/_scale480p.yuv \\\n",
      "-map '[d]' -f rawvideo -pix_fmt nv12 -y /tmp/_scale240p.yuv\n",
      "```\n",
      "\n",
      "This command uses the `scaler_ama` filter to scale the input H.264 file into four different resolutions: 1080p, 720p, 480p, and 240p. The scaled outputs are then saved as RAW files in YUV420 format under `/tmp/_scale<resolution>.yuv`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5440b5de901740f2b073e384d4e8f76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:03:46 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question7:  Using ffmpeg one cmd line, decodes an existing H.264 file and then using scaler_ama scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:You can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -c:v h264_ama -i <INPUT> -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full)(1280x720|half)(720x480|half)(360x240|half) [a][b][c][d];[a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\" -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "```\n",
      "\n",
      "This command will decode the input H.264 file, scale it to 4 different resolutions (1080p, 720p, 480p, and 240p), and save the RAW outputs to disk under `/tmp/<resolution>.yuv`.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4dfc9e11e2452f895c9c38b792612c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:03:51 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question8: How to tuning Latency of MA35D ama codec video transcode,  for example enable ultra low latency for ama_av1 Encoding?\n",
      "Answer:Based on the provided information, to tune the latency of MA35D AMA codec video transcode, specifically enabling Ultra Low Latency (ULL) mode for `ama_av1` encoding, you can use the following command:\n",
      "\n",
      "```\n",
      "ffmpeg -y -hwaccel ama -hwaccel_device /dev/ama_transcoder0 -s 1920x1080 -framerate 60 -pix_fmt yuv420p -i <INPUT> -vf hwupload -c:v av1_ama -tune_metrics 4 -lookahead_depth 0 -b:v 2M -f rawvideo <OUTPUT>\n",
      "```\n",
      "\n",
      "This command enables ULL mode by setting `lookahead_depth` to 0, which reduces the latency at the cost of increased bit rate. You can adjust other parameters such as `b:v` and `tune_metrics` to achieve a balance between latency and quality.\n",
      "\n",
      "Note that this is just an example command, and you may need to modify it based on your specific use case and requirements.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a407caca3f9f48d390bca546af0df6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:03:59 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question9: 一个ma35D AV1 codec transcode 的处理能力是多少 \n",
      "Answer:Based on the provided information, the MA35D card can perform transcoding with an aggregate rate of up to four 4Kp60 for AV1 format per VPU.\n",
      "\n",
      "Since the question is asking about the processing power of a single MA35D AV1 codec transcode, I will provide an answer based on that assumption. According to the information provided, the video processing power of the MA35D cards can be harnessed in many different ways, from running a few high-definition jobs to running many low-resolution ones, with or without scaling.\n",
      "\n",
      "The tables below show how many jobs can be run at real-time speed based on the use case and the number of cards available. All these configurations have been tested and validated by AMD and assume normal operating ranges.\n",
      "\n",
      "Note that in the following tables, density numbers linearly scale to up to 16 devices. It is assumed that per device, host chassis has set aside 8 hyper-threaded cores with 12GB of RAM.\n",
      "\n",
      "For a single MA35D card, running a 10.80p60 AV1 Type-1 encode will result in the following output:\n",
      "\n",
      "* Encoder options:\n",
      "\t+ -c:v av1_ama\n",
      "\t+ -device_type 1 (Xilinx)\n",
      "\t+ -b:v 50000K (50 Mbps)\n",
      "\t+ -fps 30\n",
      "\t+ -g 12\n",
      "\t+ -max-bitrate -1\n",
      "\t+ -min_qp 0\n",
      "\t+ -max_qp 51\n",
      "\t+ -spatial_aq_gain 255\n",
      "\t+ -temporal_aq_gain 255\n",
      "\t+ -bf 2\n",
      "\n",
      "According to the output, the MA35D card is using approximately 25% of its processing power for encoding.\n",
      "\n",
      "Therefore, the processing power of a single MA35D AV1 codec transcode is approximately 25%.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f352a1e18c004ceeb0ca8d6fac43e65f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:04:05 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question10: Is max_bitrate implemented in ama sdk ffmpeg, and is it correct that the max bitrate parameter in AMA is irrelevant to VBR?\n",
      "Answer:Based on the provided information, I can answer your question as follows:\n",
      "\n",
      "The `max_bitrate` option is not explicitly mentioned in the FFmpeg documentation for the AMA (AMD Multimidia Accelerator) device. However, it is possible that this option may be implemented in the AMA SDK FFmpeg wrapper.\n",
      "\n",
      "Regarding the second part of your question, according to the FFmpeg documentation for the libtheora encoder, the `max_bitrate` option is indeed irrelevant when VBR (Variable Bit Rate) mode is enabled. This is because the bitrate is automatically adjusted based on the quality target specified by the `qscale` flag.\n",
      "\n",
      "In summary:\n",
      "\n",
      "1. The `max_bitrate` option may be implemented in the AMA SDK FFmpeg wrapper, but this information is not explicitly documented.\n",
      "2. When VBR mode is enabled with the `flags +qscale` option, the `max_bitrate` parameter becomes irrelevant and the bitrate is adjusted based on the quality target specified by the `qscale` flag.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# questions = [\n",
    "#    \"一个ma35D AV1 codec 能处理1080p的数据流最大到多少fps \",\n",
    "#     \"\"\"for MA35D video transcode, how to tuning Latency,  for example enable ultra low latency for ama_av1 Encoding?\"\"\",\n",
    "#    \"\"\"does AMA SDK FFmpeg implement `max_bitrate`, Is max_bitrate implemented in ma35d sdk ffmpeg, and is it correct that the max bitrate parameter in AMA is irrelevant to VBR?\"\"\",\n",
    "# ]\n",
    "\n",
    "counter = 0\n",
    "for question in questions:\n",
    "   counter = counter + 1\n",
    "   query_response = query_engine_tree_summarize.query(question)\n",
    "   print(f\"Question{counter}: {question}\")\n",
    "   print(f\"Answer:{query_response.response}\")\n",
    "\n",
    "   print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:text_qa_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context_str}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: {query_str}\n",
      "Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Prompt Key**: response_synthesizer:refine_template<br>**Text:** <br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original query is as follows: {query_str}\n",
      "We have provided an existing answer: {existing_answer}\n",
      "We have the opportunity to refine the existing answer (only if needed) with some more context below.\n",
      "------------\n",
      "{context_msg}\n",
      "------------\n",
      "Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\n",
      "Refined Answer: \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "query_engine_refine = index.as_query_engine(response_mode='refine', similarity_top_k=20)\n",
    "\n",
    "template = (\n",
    "    \"You are video transcode expert and very faimilay with ffmpge and expecially good at MA35D AMA(AMD multimidia accelerator) device encode/decode/scale/transcode.\\.\\n\"\n",
    "    \"Context information from multiple sources is below.\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"Given the information from multiple sources and not prior knowledge\\n\"\n",
    "    \"please read the above context information carefully. and anwer the question.\\n\"\n",
    "    \"if the question is not releate with video process, just say it is not releated with my knowledge base.\\n\"\n",
    "    \"if you don't know the answer, just say that I don't know.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"if the question is in chinese, please transclate chinese to english in advance\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_template}\n",
    ")\n",
    "\n",
    "\n",
    "template = (\n",
    "    \"The original query is as follows: {query_str}.\\n\"\n",
    "    \"We have provided an existing answer: {existing_answer}.\\n\"\n",
    "    \"We have the opportunity to refine the existing answer (only if needed) with some more context below.\\n\"\n",
    "    \"-------------\\n\"\n",
    "    \"{context_msg}\\n\"\n",
    "    \"-------------\\n\"\n",
    "    \"Given the new context, refine the original answer to better answer the query. If the context isn't useful, return the original answer.\\n\"\n",
    "    \"if the question is 'who are you' , just say I am a video expert.\\n\"\n",
    "    \"Answers need to be precise and concise.\\n\"\n",
    "    \"Refined Answer: \"\n",
    ")\n",
    "\n",
    "\n",
    "qa_template = PromptTemplate(template)\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:refine_template\": qa_template}\n",
    ")\n",
    "\n",
    "prompts_dict = query_engine_refine.get_prompts()\n",
    "display_prompt_dict(prompts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5baceee5e3c4c18932c4abe3d261d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:04:08 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:11 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:13 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:14 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:16 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:17 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:19 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:20 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:22 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:24 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:27 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:31 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:33 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:37 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:40 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:42 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question1: explain following ffmpeg command \"ffmpeg -hwaccel ama -f rawvideo -s 1920x1080 -framerate 24 -i cut1_1080p.nv12 -vf 'hwupload' -c:v av1_ama -b:v 5M -f mp4 -y 1.av1_1080p_1.mp4\" \n",
      "Answer:Here's a rewritten answer for the given FFmpeg command:\n",
      "\n",
      "This command uses FFmpeg to encode an input video stream using the AV1 codec with AMA acceleration, and save it as an MP4 file.\n",
      "\n",
      "The command starts by specifying the input format as raw video, resolution as 19,200x10,800 pixels, and frame rate as 24 frames per second. The input file is a raw video stream in NV12 format.\n",
      "\n",
      "Next, the `hwupload` filter is applied to upload the video data to the hardware accelerator for processing. The video codec is set to AV1 with AMA acceleration, and the bitrate is set to 5 megabits per second.\n",
      "\n",
      "Finally, the output file is saved as an MP4 file named `1.av1_10p_1.mp4`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65b7f0a6f420472a8e256e1820110b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:04:49 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:04:55 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:02 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:08 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:14 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:20 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:26 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:32 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:38 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:40 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:44 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:47 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:49 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:52 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:55 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:05:57 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:00 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question2: explain following ffmpeg command\n",
      "   ffmpeg -y -hwaccel ama       -c:v h264_ama  -out_fmt nv12 -i <INPUT>        -filter_complex \"scaler_ama=outputs=4:out_res=(1920x1080|full|nv12)(1280x720|full|nv12)(720x480|full|nv12)(360x240|full|nv12) [a][b][c][d];                      [a]hwdownload,format=nv12[a1];[b]hwdownload,format=nv12[b1];[c]hwdownload,format=nv12[c1];[d]hwdownload,format=nv12[d1]\"       -map '[a1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_1080p.yuv       -map '[b1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_720p.yuv        -map '[c1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_480p.yuv       -map '[d1]' -f rawvideo -pix_fmt nv12 -y /tmp/scale_240p.yuv\n",
      "Answer:Here's a rewritten answer based on the new context:\n",
      "\n",
      "This FFmpeg command is used to generate multiple output files with different resolutions (10.80p, 720p, 480p, and 240p) from a single input file. The command uses the `filter_complex` option to apply a scaler filter that generates four separate video streams.\n",
      "\n",
      "The scaler filter takes the input video and scales it to four different resolutions using the `scaler_ama` filter. Each output stream is then mapped to a separate file using the `-map` option, with each file being saved in raw YUV format.\n",
      "\n",
      "By utilizing hardware acceleration for the scaler filter, this command can potentially improve performance when processing large input files or high-resolution video streams.\n",
      "\n",
      "(Note: I rewrote the answer to fit the new context without referencing the original answer directly.)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ac866ef39c46cebe0affc78e30a728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:06:02 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:03 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:05 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:08 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:09 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:11 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:12 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:14 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:15 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:17 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:18 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:20 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:21 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:23 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:24 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:25 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:27 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:28 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question3: Using ffmpeg Decoder a clip that is already encoded in H.264, and will decode the file into a RAW format and save it to disk.\n",
      "Answer:Here's the rewritten answer:\n",
      "\n",
      "To decode a clip that is already encoded in H.264 and save it to disk as RAW format without re-encoding, you can use the following command:\n",
      "ffmpeg -i input -c:v rawvideo -f rawvideo /tmp/<resolution>.yuv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d821a626155046678f70362eb5806dae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:06:29 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:32 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:33 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:35 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:37 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:39 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:40 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:42 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:44 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:46 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:49 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:51 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:53 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:55 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:57 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:06:58 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:00 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:02 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:04 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question4: Using ffmpeg encode a RAW 1080p60 clip in YUV420 format. Pass the clip to the MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and saves it to disk. please do not use -re option\n",
      "Answer:Here's the rewritten answer based on the new context:\n",
      "\n",
      "To encode a RAW 10.80p60 clip in YUV420 format using ffmpeg and produce an AV1 encoded MP4 output with a target bitrate of 5Mbps, you can use the following command:\n",
      "```ffmpeg -i input.mp4 -c:v av1_amf -b:v 5M -g 60 output.mp4```\n",
      "Note that I've replaced `libma35d` with `av1_amf`, which is the correct encoder for AV1 encoding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6877b0065427475a9b19930ee757f658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:07:06 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:09 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:11 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:12 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:15 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:17 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:19 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:21 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:23 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:25 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:27 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:29 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:32 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:34 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:36 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:38 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:40 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:41 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question5:  Using ffmpeg do the Bit Conversion, To encode YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format' \n",
      "Answer:Here's a rewritten answer based on the new context:\n",
      "\n",
      "To convert YUV 4:2:2 10-bit pixel format to YUV 4:2:0 8-bit format using FFmpeg, you can use the following command:\n",
      "\n",
      "    ffmpeg -i input -f null -c:v mpeg4 -pix_fmt yuv420p -\n",
      "\n",
      "This will perform the bit conversion and discard the output.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191c011e60794827aefcf34f3ef12ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:07:47 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:53 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:07:58 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:03 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:08 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:13 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:18 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:20 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:21 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:23 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:27 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:32 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:36 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:40 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:42 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:44 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:46 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:48 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question6:  Using ffmpeg decodes an existing H.264 file and then scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:Here's a rewritten answer based on the new context:\n",
      "\n",
      "To scale an existing H.264 file into different resolutions (1080p, 720p, 480p, and 240p) and save the RAW outputs to disk at real-time speed, you can use the following command:\n",
      "\n",
      "```ffmpeg -re -i input -filter_complex \"scale=w=<WIDTH>,h=<HEIGHT>\" -f rawvideo -pix_fmt yuv420p /tmp/scale_<RESOLUTION>.yuv\n",
      "```\n",
      "\n",
      "Replace `<WIDTH>` and `<HEIGHT>` with the desired values for each resolution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8503f57f824962ad4d85d1474d6d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:08:52 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:08:57 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:02 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:06 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:11 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:15 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:18 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:20 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:22 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:24 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:26 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:28 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:32 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:34 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:37 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:39 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:41 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:43 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question7:  Using ffmpeg one cmd line, decodes an existing H.264 file and then using scaler_ama scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\n",
      "Answer:Here's a rewritten answer that takes into account the new context:\n",
      "\n",
      "To scale an existing H.264 file using ffmpeg one cmd line, you can use the following command:\n",
      "```\n",
      "ffmpeg -i input.h264 -vf scaler_ama=outputs=4:out_res=[1080],[720],[480],[240] -c:v libx265 -f rawvideo -pix_fmt nv12 -o out1.nv12\n",
      "```\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b26a1b965d4cfdb29c588ceb0f347c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:09:45 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:48 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:50 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:53 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:54 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:56 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:57 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:09:59 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:05 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:07 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:08 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:09 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:11 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:13 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:15 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:16 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:17 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:19 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:21 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:23 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question8: How to tuning Latency of MA35D ama codec video transcode,  for example enable ultra low latency for ama_av1 Encoding?\n",
      "Answer:To tune the latency of MA35D AMA codec video transcode for ultra low latency, consider using x264's `-tune zerolatency` option. This can help reduce the delay while maintaining acceptable visual quality. Additionally, you can experiment with different buffer sizes and Look Ahead Depths to find the optimal balance between latency and quality.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b8c2c142914723a54060d7760aba66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:10:25 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:27 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:28 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:29 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:29 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:30 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:32 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:34 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:35 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:37 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:39 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:41 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:43 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:45 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:47 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:49 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:52 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:54 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:10:56 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question9: 一个ma35D AV1 codec transcode 的处理能力是多少 \n",
      "Answer:The processing capacity of an MA35D AV1 codec transcode depends on various factors such as resolution, frame rate, and pixel format. For instance, if we consider a high-resolution stream with a single video plane storing alpha mask, the load would be approximately 12.5% of the device's total capacity. This means that the MA35D AV1 codec transcode can handle multiple streams depending on their resolutions and frame rates.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d10ec7836124167bee0debcd96ba65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2024 10:10:58 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:01 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:04 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:07 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:08 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:10 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:13 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:15 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:17 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:19 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:21 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:24 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:26 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:28 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:30 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:33 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:35 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:37 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:39 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n",
      "04/26/2024 10:11:41 - [INFO] -httpx->>>    HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question10: Is max_bitrate implemented in ama sdk ffmpeg, and is it correct that the max bitrate parameter in AMA is irrelevant to VBR?\n",
      "Answer:**Rewrite**\n",
      "\n",
      "The `max_bitrate` parameter is implemented in AMA SDK FFmpeg. However, it's correct that this parameter is irrelevant to Variable Bitrate (VBR) encoding. The algorithm focuses on overall encoding quality while meeting the specified bitrate, target_bitrate, within the accuracy range avbr_accuracy, after a avbr_Convergence period. This method does not follow HRD and the instant bitrate is not capped or padded.\n",
      "\n",
      "In VBR mode, FFmpeg adjusts the bitrate based on the complexity of the video content to achieve the desired quality. The `max_bitrate` parameter only applies when using Constant Bitrate (CBR) encoding, where the bitrate remains constant throughout the entire video.\n"
     ]
    }
   ],
   "source": [
    "# questions = [\n",
    "#    \"\"\"Using ffmpeg Decoder a clip that is already encoded in H.264, and will decode the file into a RAW format and save it to disk.\"\"\",\n",
    "#    \"\"\"Using ffmpeg encode a RAW 1080p60 clip in YUV420 format. Pass the clip to the MA35D encoder to produce an AV1 encoded MP4 output with a target bitrate of 5Mbps and saves it to disk. please do not use -re option\"\"\",\n",
    "#    \"\"\" Using ffmpeg do the Bit Conversion, To encode YUV 4:2:2 10 bit pixel format to YUV 4:2:0 8 bit format' \"\"\",\n",
    "#    \"\"\" Using ffmpeg decodes an existing H.264 file and then scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\"\"\",\n",
    "#    \"\"\" Using ffmpeg one cmd line, decodes an existing H.264 file and then using scaler_ama scales it into 1080p/720p/480p/240p four resolutions and save the RAW outputs to disk under\"\"\",\n",
    "#    # \"\"\"ffmpeg命令使用ma35d硬件转码, 用一条命令行使用split方式，将一个h264 4k60的文件同时转码成两个hevc和av1格式的文件,写出具体的命令行例子\"\"\"\n",
    "# ]\n",
    "\n",
    "counter = 0\n",
    "for question in questions:\n",
    "   counter = counter + 1\n",
    "   # query_engine = index.as_query_engine()\n",
    "   query_response = query_engine_refine.query(question)\n",
    "   print(f\"Question{counter}: {question}\")\n",
    "   print(f\"Answer:{query_response.response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions = [\n",
    "\n",
    "# ]\n",
    "\n",
    "# counter = 0\n",
    "# for question in questions:\n",
    "#    counter = counter + 1\n",
    "#    query_engine = index.as_query_engine()\n",
    "#    query_response = query_engine.query(question)\n",
    "#    print(f\"Question{counter}: {question}\")\n",
    "#    print(f\"Answer:{query_response.response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
